{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aeWEr7SVACGP",
    "outputId": "4d7a9ff4-0013-4304-cb24-6d1b78dce7b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting trimesh\n",
      "  Downloading trimesh-3.9.39-py3-none-any.whl (640 kB)\n",
      "\u001b[K     |████████████████████████████████| 640 kB 6.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from trimesh) (57.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from trimesh) (1.19.5)\n",
      "Installing collected packages: trimesh\n",
      "Successfully installed trimesh-3.9.39\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install trimesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lzg3HwMO_5vD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 16:39:07.300697: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import glob\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Conv3D, Dense ,Dropout, Flatten, Activation, MaxPooling3D, Input\n",
    "from tensorflow.keras.layers import Convolution2D,Conv2D, Dense,Dropout, Flatten, Activation, MaxPooling2D, Input, Conv1D, GlobalAveragePooling1D, TimeDistributed, GRU, LSTM\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold,StratifiedKFold\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nrAEYus-AVcE",
    "outputId": "fde9232d-ef59-41d4-9c01-cf466fa5feb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading from disk\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    print(\"reading from cloud...\")\n",
    "    path = \"/content/drive/MyDrive/Colab Notebooks/MPPE/data_70p_overhang/stls_opt/\"\n",
    "    path_vox = \"/content/drive/MyDrive/Colab Notebooks/MPPE/data_70p_overhang/voxelsFloat/\"\n",
    "     \n",
    "    path = \"/content/drive/MyDrive/data_70p_overhang/stls_opt/\"\n",
    "    path_vox = \"/content/drive/MyDrive/data_70p_overhang/voxelsFloat/\"\n",
    "    path_split = \"/content/drive/MyDrive/data_70p_overhang/12/\"\n",
    "\n",
    "except:\n",
    "    import pathlib\n",
    "    print(\"reading from disk\")\n",
    "    path = str(pathlib.Path().resolve())+\"/dataset/stls_opt/\"\n",
    "    path_vox = str(pathlib.Path().resolve())+\"/dataset/voxels/\"\n",
    "    path_split = str(pathlib.Path().resolve())+\"/dataset/42/\"\n",
    "\n",
    "\n",
    "mesh = trimesh.load(path+\"63_8475_10313_17790_28845.stl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_HKy6ANOZvOG",
    "outputId": "7c72b65a-f8c2-43fe-d50b-b3c99f38556b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.46582523917991\n"
     ]
    }
   ],
   "source": [
    "def calculate_cost(filename):\n",
    "  #params\n",
    "  #time - parts usally need 15 minutes for preparation\n",
    "  #1h - 10eur\n",
    "  price_per_h = 2\n",
    "  price_per_meter = 0.17#0.1133 #150 meters costs 17e \n",
    "  filament_diameter = 2.85 #mm\n",
    "  filament_phi = np.power(filament_diameter/2,2)*np.pi #mm^2\n",
    "  \n",
    "  support_removal_multiplier= 2\n",
    "  support_removal_multiplier_time = 1.5\n",
    "  profit_margin = 0.1\n",
    "  #larger parts need longer time + 5 minutes slice time. \n",
    "  \n",
    "  #get data from filename\n",
    "  data = filename.replace(\".\",\"_\").split(\"_\")\n",
    "  data = [int(x) for x in data[:-1]]\n",
    "\n",
    "  #calculate cost from filament lenght\n",
    "\n",
    "  #calulate cost no support \n",
    "  cost_filament = ((data[2]/(filament_phi*1000)))*price_per_meter\n",
    "\n",
    "  #calulcate cost of printing supports only \n",
    "  cost_supports = (abs(data[2]-data[4])/(filament_phi*1000))*price_per_meter\n",
    "  cost_supports_removal = support_removal_multiplier*cost_supports\n",
    "\n",
    "  #calulate timewise cost in hours\n",
    "  print_time = data[1]\n",
    "  print_time_supports = data[3]\n",
    "\n",
    "  #convert to horus and include time for removing supports \n",
    "  print_time= (((print_time + 2*abs(print_time-print_time_supports))*support_removal_multiplier_time)/3600)\n",
    "  print_time_cost = print_time * price_per_h\n",
    "\n",
    "  #cena\n",
    "  cost = (cost_filament+cost_supports+cost_supports_removal+print_time_cost)\n",
    "  cost = (cost*profit_margin)+cost\n",
    "\n",
    "  return cost\n",
    "\n",
    "#cost = calculate_cost(\"89_88123_134991_106833_152824.stl\")\n",
    "#cost = calculate_cost(\"62_1605_2129_2398_3618.stl\")\n",
    "cost = calculate_cost(\"108_31956_48635_34435_50936.stl\")\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s7xD2c4KsFHj",
    "outputId": "2103b4e4-c7c1-4741-a9af-74d1ba7ff3cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros([0,100,100,100])\n",
    "X_volume = np.zeros([0,1])\n",
    "X_area = np.zeros([0,1])\n",
    "\n",
    "y = np.zeros(0)\n",
    "count = 0\n",
    "for filename in os.listdir(path_vox):\n",
    "    if filename.endswith(\".npy\"):\n",
    "        count = count +1\n",
    "        #print(\"appending\", filename.split(\".\")[0])\n",
    "        img = np.load(path_vox+filename)\n",
    "\n",
    "        img =(img -(np.min(img)))\n",
    "        img = img/np.max(img)\n",
    "        cost = calculate_cost(filename)\n",
    "        \n",
    "        img = np.swapaxes(img,0,-1)\n",
    "\n",
    "        X = np.append(X,img[np.newaxis,...],axis=0)\n",
    "        y = np.append(y,cost)\n",
    "        \n",
    "        mesh = trimesh.load(path+filename.split(\".\")[0]+\".stl\")\n",
    "        \n",
    "        mv = np.array(abs(mesh.volume))\n",
    "        X_volume = np.append(X_volume,mv[np.newaxis,...])\n",
    "\n",
    "        ma = np.array(abs(mesh.area))\n",
    "        X_area = np.append(X_area,ma[np.newaxis,...])\n",
    "\n",
    "print(count)\n",
    "X_area = X_area[...,np.newaxis]\n",
    "X_volume = X_volume[...,np.newaxis]\n",
    "X = X[...,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TvrJA9v_deq8",
    "outputId": "271b908c-81c3-4cd1-e8d1-05608c6ab1f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (150, 100, 100, 100, 1) (150, 1) (150, 1)\n",
      "test (38, 100, 100, 100, 1) (38, 1) (38, 1)\n"
     ]
    }
   ],
   "source": [
    "n_samples = X.shape[0]\n",
    "train_ind, test_ind  = train_test_split(range(n_samples), test_size=0.2, random_state=36)\n",
    "\n",
    "X_train = X[train_ind]\n",
    "X_train_volume = X_volume[train_ind]\n",
    "X_train_area = X_area[train_ind]\n",
    "y_train = y[train_ind]\n",
    "\n",
    "X_test = X[test_ind]\n",
    "X_test_volume = X_volume[test_ind]\n",
    "X_test_area = X_area[test_ind]\n",
    "y_test = y[test_ind]\n",
    "\n",
    "print(\"train\",X_train.shape,X_train_volume.shape,X_train_area.shape)\n",
    "print(\"test\",X_test.shape,X_test_volume.shape,X_test_area.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kEodXrjKt37C"
   },
   "outputs": [],
   "source": [
    "def augment(img,angle):\n",
    "\n",
    "  img = scipy.ndimage.rotate(img,angle,axes=(0,1),order=3)\n",
    "  n = 100\n",
    "  desiredshape = np.array([n,n,n])\n",
    "  zoomArray = desiredshape.astype(np.float32) / img.shape\n",
    "  img = scipy.ndimage.interpolation.zoom(img, zoomArray).astype(np.float32)\n",
    "  \n",
    "  img =(img -(np.min(img)))\n",
    "\n",
    "  img = img/np.max(img)\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "RgJvpdbRvJlv",
    "outputId": "e38ac1fc-d692-426f-8515-457b49e0ce5d"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_49236/2557264858.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mimg_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mangle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mX_train_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_aug\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mX_train_volume_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_volume_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train_volume\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mX_train_area_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_area_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train_area\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mappend\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   4669\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4670\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4671\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train_2 = np.zeros([0,100,100,100])\n",
    "X_train_volume_2 = np.zeros([0,1])\n",
    "X_train_area_2 = np.zeros([0,1])\n",
    "y_train_2 = np.zeros(0)\n",
    "\n",
    "for i,img in enumerate(X_train):\n",
    "  for angle in range(0,330,30):\n",
    "    img_aug = augment(img[:,:,:,0],angle)\n",
    "\n",
    "    X_train_2 = np.append(X_train_2,img_aug[np.newaxis,...],axis=0)\n",
    "    X_train_volume_2 = np.append(X_train_volume_2,X_train_volume[i])\n",
    "    X_train_area_2 = np.append(X_train_area_2,X_train_area[i])\n",
    "\n",
    "    y_train_2 = np.append(y_train_2,y_train[i])\n",
    "  \n",
    "X_train_area_2 = X_train_area_2[...,np.newaxis]\n",
    "X_train_volume_2 = X_train_volume_2[...,np.newaxis]\n",
    "X_train_2 = X_train_2[...,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B-_n02ejeLQM",
    "outputId": "7d178c26-819b-4aa8-ea38-9eea7c51037b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3GQ8VtdUmUGX"
   },
   "outputs": [],
   "source": [
    "X_train = np.load(path_split+\"/X_train.npy\")\n",
    "X_train_volume = np.load(path_split+\"/X_train_volume.npy\")\n",
    "X_train_area = np.load(path_split+\"/X_train_area.npy\")\n",
    "y_train = np.load(path_split+\"/y_train.npy\")\n",
    "\n",
    "X_test = np.load(path_split+\"/X_test.npy\")\n",
    "X_test_volume = np.load(path_split+\"/X_test_volume.npy\")\n",
    "X_test_area = np.load(path_split+\"/X_test_area.npy\")\n",
    "y_test = np.load(path_split+\"/y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RdmXZxvi9Tbn"
   },
   "outputs": [],
   "source": [
    "X_train_volume = X_trian_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "d45eX3H0lw12"
   },
   "outputs": [],
   "source": [
    "#my net\n",
    "input1 = keras.Input(shape=(X_train.shape[1:]))\n",
    "input2 = keras.Input(shape=(X_train_volume.shape[1:]))\n",
    "input3 = keras.Input(shape=(X_train_area.shape[1:]))\n",
    "\n",
    "#y = Dense(1)(input2)\n",
    "activ = \"LeakyReLU\"\n",
    "# x = Conv3D(64,(7,7,7),strides = (2,2,2), activation=activ, padding = 'same')(input1)\n",
    "# x = Conv3D(64,(7,7,7),strides = (2,2,2), activation=activ, padding = 'same')(x)\n",
    "# x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "# x = layers.Dropout(0.3)(x)\n",
    "n=3\n",
    "x = Conv3D(32,(n,n,n),strides = (2,2,2), activation=activ, padding = 'same')(input1)\n",
    "x = Conv3D(32,(n,n,n),strides = (2,2,2), activation=activ, padding = 'same')(x)\n",
    "x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = Conv3D(16,(n,n,n), activation=activ, padding = 'same')(x)\n",
    "x = Conv3D(16,(n,n,n),strides = (2,2,2), activation=activ, padding = 'same')(x)\n",
    "x = MaxPooling3D(pool_size=(1, 1, 1))(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = Conv3D(8,(n,n,n),strides = (2,2,2), activation=activ, padding = 'same')(x)\n",
    "x = Conv3D(8,(n,n,n),strides = (2,2,2), activation=activ, padding = 'same')(x)\n",
    "x = MaxPooling3D(pool_size=(1, 1, 1))(x)\n",
    "\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = layers.Concatenate(axis=1)([x,input2])\n",
    "#x = Dense(4, activation = 'relu')(x)\n",
    "x = layers.Concatenate(axis=1)([x,input3])\n",
    "\n",
    "dense = Dense(2000, activation = activ)(x)\n",
    "dense = Dense(300, activation = activ)(dense)\n",
    "dense = Dense(150, activation = activ)(dense)\n",
    "dense = Dense(20, activation = activ)(dense)\n",
    "dense = Dense(16, activation = activ)(dense)\n",
    "    # final layer with 10 neurons to classify the instances\n",
    "output = Dense(1, activation = 'linear')(dense)\n",
    "    \n",
    "#outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=[input1,input2,input3], outputs=output, name=\"jjnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ofDFz7RL-14E"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-04 15:49:04.736439: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-04 15:49:04.791234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 0 with properties: \n",
      "pciBusID: 0000:21:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-01-04 15:49:04.791282: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-04 15:49:04.794915: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcublas.so.11\n",
      "2022-01-04 15:49:04.794999: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-01-04 15:49:04.796733: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-04 15:49:04.797072: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-04 15:49:04.797793: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcutensor.so.1\n",
      "2022-01-04 15:49:04.798276: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-01-04 15:49:04.798965: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-01-04 15:49:04.799169: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-01-04 15:49:04.799572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1872] Adding visible gpu devices: 0\n",
      "2022-01-04 15:49:04.801189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 0 with properties: \n",
      "pciBusID: 0000:21:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-01-04 15:49:04.801518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1872] Adding visible gpu devices: 0\n",
      "2022-01-04 15:49:04.801554: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-04 15:49:05.185060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-01-04 15:49:05.185100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-01-04 15:49:05.185107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-01-04 15:49:05.185691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9649 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:21:00.0, compute capability: 7.5)\n",
      "2022-01-04 15:49:05.185989: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 20. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "input1 = keras.Input(shape=(X_train.shape[1:]))\n",
    "input2 = keras.Input(shape=(X_train_volume.shape[1:]))\n",
    "input3 = keras.Input(shape=(X_train_area.shape[1:]))\n",
    "\n",
    "activ = \"relu\"\n",
    "\n",
    "# x = TimeDistributed(Convolution2D(32, (7, 7), activation='relu', padding='same'))(input1)\n",
    "# x = TimeDistributed(Convolution2D(32, (7, 7), activation='relu', padding='same'))(x)\n",
    "# x = TimeDistributed(MaxPooling2D(pool_size=(2, 2), padding='same'))(x)\n",
    "\n",
    "x = TimeDistributed(Convolution2D(8, (3, 3), activation='relu', padding='same'))(input1)\n",
    "x = TimeDistributed(Convolution2D(8, (3, 3), activation='relu', padding='same'))(x)\n",
    "x = TimeDistributed(MaxPooling2D(pool_size=(2, 2), padding='same'))(x)\n",
    "x = TimeDistributed(Convolution2D(4, (3, 3), activation='relu', padding='same'))(x)\n",
    "x = TimeDistributed(Convolution2D(4, (3, 3), activation='relu', padding='same'))(x)\n",
    "x = TimeDistributed(MaxPooling2D(pool_size=(2, 2), padding='same'))(x)\n",
    "x = Dropout(0.30)(x)\n",
    "\n",
    "x = TimeDistributed(Convolution2D(4, (3, 3), activation='relu', padding='same'))(x)\n",
    "x = TimeDistributed(Convolution2D(4, (3, 3), activation='relu', padding='same'))(x)\n",
    "x = TimeDistributed(MaxPooling2D(pool_size=(2, 2), padding='same'))(x)\n",
    "x = Dropout(0.30)(x)\n",
    "x = TimeDistributed(Flatten())(x)\n",
    "x = LSTM(8, return_sequences=True, unroll=False, dropout=0.3)(x)  # dropout=0.6\n",
    "x = LSTM(8, return_sequences=False, unroll=False, dropout=0.3)(x)\n",
    "\n",
    "\n",
    "x = layers.Concatenate(axis=1)([x,input2])\n",
    "\n",
    "#x = Dense(4, activation = 'relu')(x)\n",
    "x = layers.Concatenate(axis=1)([x,input3])\n",
    "\n",
    "dense = Dense(2000, activation = activ)(x)\n",
    "dense = Dense(300, activation = activ)(dense)\n",
    "dense = Dense(150, activation = activ)(dense)\n",
    "dense = Dense(20, activation = activ)(dense)\n",
    "dense = Dense(16, activation = activ)(dense)\n",
    "    # final layer with 10 neurons to classify the instances\n",
    "output = Dense(1, activation = 'linear')(dense)\n",
    "    \n",
    "\n",
    "model = keras.Model(inputs=[input1,input2,input3], outputs=output, name=\"jjlstmnet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "5NctJfQTgfIE"
   },
   "outputs": [],
   "source": [
    "#@title Default title text\n",
    "#paper net \n",
    "input1 = keras.Input(shape=(X_train.shape[1:]))\n",
    "input2 = keras.Input(shape=(X_train_volume.shape[1:]))\n",
    "input3 = keras.Input(shape=(X_train_area.shape[1:]))\n",
    "\n",
    "\n",
    "\n",
    "x = Conv3D(16,(3,3,3), activation='LeakyReLU', padding = 'same')(input1)\n",
    "x = Conv3D(16,(3,3,3), activation='LeakyReLU', padding = 'same')(x)\n",
    "x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = Conv3D(32,(3,3,3), activation='LeakyReLU', padding = 'same')(x)\n",
    "x = Conv3D(32,(3,3,3), activation='LeakyReLU', padding = 'same')(x)\n",
    "x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = Conv3D(8,(3,3,3), activation='LeakyReLU', padding = 'same')(x)\n",
    "\n",
    "x = layers.Dropout(0.8)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = layers.Concatenate(axis=1)([x,input2])\n",
    "x = Dense(8, activation = 'LeakyReLU')(x)\n",
    "dense = Dense(2000, activation = 'LeakyReLU')(x)\n",
    "dense = Dense(300, activation = 'LeakyReLU')(dense)\n",
    "dense = Dense(150, activation = 'LeakyReLU')(dense)\n",
    "dense = Dense(20, activation = 'LeakyReLU')(dense)\n",
    "dense = Dense(16, activation = 'LeakyReLU')(dense)\n",
    "    # final layer with 10 neurons to classify the instances\n",
    "output = Dense(1, activation = 'linear')(dense)\n",
    "    \n",
    "#outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=[input1,input2], outputs=output, name=\"papernet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AIUls8_FqAYq"
   },
   "outputs": [],
   "source": [
    "def min_max(val):\n",
    "  val =(val -(np.min(val)))\n",
    "  val = val/np.max(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "765aPkAD_5vR",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.0719 - MAPE: 11.6998\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0668 - MAPE: 5.8661\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0640 - MAPE: 6.2092\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0684 - MAPE: 6.1603\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0751 - MAPE: 8.2276\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0735 - MAPE: 11.5637\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0708 - MAPE: 7.6593\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0675 - MAPE: 5.8584\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0679 - MAPE: 6.4529\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0712 - MAPE: 10.3728\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0709 - MAPE: 6.1991\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0695 - MAPE: 10.5727\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0740 - MAPE: 5.6250\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0693 - MAPE: 8.0612\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0686 - MAPE: 7.7433\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0764 - MAPE: 10.6760\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0689 - MAPE: 5.8526\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0629 - MAPE: 6.8628\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0717 - MAPE: 7.1581\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.0620 - MAPE: 6.7640\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0635 - MAPE: 5.3154\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0704 - MAPE: 7.6081\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0726 - MAPE: 9.1657: 0s - loss: 0.0726 - MAPE: 9.16\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0619 - MAPE: 8.7091\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0681 - MAPE: 6.2679\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0624 - MAPE: 6.2868\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0665 - MAPE: 6.3093\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0592 - MAPE: 6.1744\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0755 - MAPE: 10.8985\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0672 - MAPE: 8.3625\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0719 - MAPE: 7.5352\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0673 - MAPE: 7.5572\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0629 - MAPE: 9.4943\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0620 - MAPE: 7.9886\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0637 - MAPE: 8.4367\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0692 - MAPE: 9.3250\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0678 - MAPE: 6.6422\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0600 - MAPE: 6.3959\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0730 - MAPE: 10.6170\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0655 - MAPE: 4.7066\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0598 - MAPE: 4.7282\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0748 - MAPE: 7.7763\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0676 - MAPE: 8.3695\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0707 - MAPE: 9.5652\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0703 - MAPE: 6.6248\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0677 - MAPE: 7.7730\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0662 - MAPE: 7.8550\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0659 - MAPE: 6.2760\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 0.0715 - MAPE: 8.1354\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0659 - MAPE: 6.8150\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0669 - MAPE: 6.1537\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0684 - MAPE: 6.7008\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0738 - MAPE: 6.0624\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0604 - MAPE: 11.1183\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0634 - MAPE: 5.2914\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0639 - MAPE: 7.7784\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0628 - MAPE: 8.8075\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0633 - MAPE: 7.8172\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0723 - MAPE: 13.9937\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0740 - MAPE: 7.9922\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0701 - MAPE: 4.9451\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0706 - MAPE: 6.5434\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0885 - MAPE: 13.9964\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0725 - MAPE: 4.7007\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0703 - MAPE: 5.8180\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0715 - MAPE: 5.9704\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.0640 - MAPE: 5.2564\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0634 - MAPE: 9.3832\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0715 - MAPE: 9.1481\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0630 - MAPE: 8.2591\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0639 - MAPE: 7.7038\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0619 - MAPE: 5.5116\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0665 - MAPE: 7.1394\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0763 - MAPE: 7.2224\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0645 - MAPE: 6.1849\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0668 - MAPE: 7.9192\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0596 - MAPE: 5.2240\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0687 - MAPE: 8.0838\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0787 - MAPE: 9.0160\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0662 - MAPE: 5.1688\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0698 - MAPE: 9.0375\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0717 - MAPE: 7.5918\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0685 - MAPE: 5.4774\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0695 - MAPE: 8.2753\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0650 - MAPE: 8.5227\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0607 - MAPE: 5.2289\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0561 - MAPE: 5.2367\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0641 - MAPE: 4.9756\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0692 - MAPE: 4.7634\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0682 - MAPE: 9.7296\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0644 - MAPE: 6.6447\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0667 - MAPE: 6.4576\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0706 - MAPE: 7.7149\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0697 - MAPE: 10.8988\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.0698 - MAPE: 6.2467\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0706 - MAPE: 7.2031\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0643 - MAPE: 6.1850\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0697 - MAPE: 7.3329\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0584 - MAPE: 7.0129\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0603 - MAPE: 5.8413\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0575 - MAPE: 8.4069\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0649 - MAPE: 5.8332\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0695 - MAPE: 7.3750\n",
      "Epoch 104/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0710 - MAPE: 6.5539\n",
      "Epoch 105/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0755 - MAPE: 6.8722\n",
      "Epoch 106/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0701 - MAPE: 6.9131\n",
      "Epoch 107/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0662 - MAPE: 6.4251\n",
      "Epoch 108/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0640 - MAPE: 5.6379\n",
      "Epoch 109/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0577 - MAPE: 6.3154\n",
      "Epoch 110/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0649 - MAPE: 6.1979\n",
      "Epoch 111/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0626 - MAPE: 9.1986\n",
      "Epoch 112/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0762 - MAPE: 7.1122\n",
      "Epoch 113/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0679 - MAPE: 11.3212\n",
      "Epoch 114/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0634 - MAPE: 6.4224\n",
      "Epoch 115/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0627 - MAPE: 7.4455\n",
      "Epoch 116/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0692 - MAPE: 8.0215\n",
      "Epoch 117/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0669 - MAPE: 12.1301\n",
      "Epoch 118/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0666 - MAPE: 5.7717\n",
      "Epoch 119/200\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 0.0746 - MAPE: 11.0996\n",
      "Epoch 120/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0707 - MAPE: 8.6136\n",
      "Epoch 121/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0624 - MAPE: 7.3818\n",
      "Epoch 122/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0695 - MAPE: 8.2440\n",
      "Epoch 123/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0722 - MAPE: 11.5847\n",
      "Epoch 124/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0632 - MAPE: 7.9303\n",
      "Epoch 125/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0641 - MAPE: 10.8925\n",
      "Epoch 126/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0631 - MAPE: 4.3437\n",
      "Epoch 127/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0621 - MAPE: 6.0133\n",
      "Epoch 128/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0672 - MAPE: 9.2418\n",
      "Epoch 129/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0659 - MAPE: 6.9280\n",
      "Epoch 130/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0746 - MAPE: 9.5059\n",
      "Epoch 131/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0663 - MAPE: 5.8757\n",
      "Epoch 132/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0583 - MAPE: 4.1520\n",
      "Epoch 133/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0694 - MAPE: 14.2678\n",
      "Epoch 134/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0730 - MAPE: 6.2205\n",
      "Epoch 135/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0680 - MAPE: 7.6045\n",
      "Epoch 136/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0755 - MAPE: 8.3569\n",
      "Epoch 137/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0723 - MAPE: 6.0242\n",
      "Epoch 138/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0662 - MAPE: 5.7523\n",
      "Epoch 139/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0605 - MAPE: 6.1665\n",
      "Epoch 140/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0655 - MAPE: 5.3961\n",
      "Epoch 141/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0707 - MAPE: 7.2478\n",
      "Epoch 142/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0630 - MAPE: 5.3093\n",
      "Epoch 143/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0654 - MAPE: 7.7994\n",
      "Epoch 144/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0655 - MAPE: 4.1376\n",
      "Epoch 145/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0616 - MAPE: 5.1148\n",
      "Epoch 146/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0681 - MAPE: 7.8929\n",
      "Epoch 147/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0662 - MAPE: 7.6316\n",
      "Epoch 148/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0614 - MAPE: 5.7831\n",
      "Epoch 149/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0691 - MAPE: 10.7177\n",
      "Epoch 150/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0619 - MAPE: 6.5092\n",
      "Epoch 151/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0709 - MAPE: 8.6521\n",
      "Epoch 152/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0700 - MAPE: 7.9531\n",
      "Epoch 153/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0598 - MAPE: 5.1445\n",
      "Epoch 154/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0676 - MAPE: 4.6946\n",
      "Epoch 155/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0639 - MAPE: 8.9346\n",
      "Epoch 156/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0642 - MAPE: 6.6986\n",
      "Epoch 157/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0690 - MAPE: 6.8559\n",
      "Epoch 158/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0607 - MAPE: 6.8204\n",
      "Epoch 159/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0595 - MAPE: 6.4206\n",
      "Epoch 160/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0605 - MAPE: 4.1695\n",
      "Epoch 161/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0643 - MAPE: 6.4713\n",
      "Epoch 162/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0641 - MAPE: 7.4684\n",
      "Epoch 163/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0739 - MAPE: 5.4922\n",
      "Epoch 164/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0597 - MAPE: 9.6302\n",
      "Epoch 165/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0734 - MAPE: 6.8136\n",
      "Epoch 166/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0627 - MAPE: 5.2325\n",
      "Epoch 167/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0683 - MAPE: 7.2080\n",
      "Epoch 168/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0704 - MAPE: 5.2883\n",
      "Epoch 169/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0631 - MAPE: 3.8251\n",
      "Epoch 170/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0691 - MAPE: 6.3742\n",
      "Epoch 171/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0681 - MAPE: 5.6383\n",
      "Epoch 172/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0696 - MAPE: 7.1060\n",
      "Epoch 173/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0638 - MAPE: 7.1690\n",
      "Epoch 174/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0677 - MAPE: 7.8690\n",
      "Epoch 175/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0620 - MAPE: 7.4674\n",
      "Epoch 176/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0695 - MAPE: 9.1960\n",
      "Epoch 177/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0637 - MAPE: 7.1114\n",
      "Epoch 178/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0633 - MAPE: 8.7197\n",
      "Epoch 179/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0654 - MAPE: 7.6911\n",
      "Epoch 180/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0642 - MAPE: 4.3940\n",
      "Epoch 181/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0639 - MAPE: 5.7755\n",
      "Epoch 182/200\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0728 - MAPE: 4.5635\n",
      "Epoch 183/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0611 - MAPE: 3.7834\n",
      "Epoch 184/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0597 - MAPE: 8.0944\n",
      "Epoch 185/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0635 - MAPE: 6.7920\n",
      "Epoch 186/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0617 - MAPE: 6.9854\n",
      "Epoch 187/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0667 - MAPE: 10.4690\n",
      "Epoch 188/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0708 - MAPE: 7.7378\n",
      "Epoch 189/200\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.0655 - MAPE: 5.4089\n",
      "Epoch 190/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0777 - MAPE: 5.8880\n",
      "Epoch 191/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0678 - MAPE: 8.3819\n",
      "Epoch 192/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0676 - MAPE: 7.9667\n",
      "Epoch 193/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0544 - MAPE: 8.1398\n",
      "Epoch 194/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0612 - MAPE: 4.6985\n",
      "Epoch 195/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0672 - MAPE: 14.5469\n",
      "Epoch 196/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0575 - MAPE: 4.8234\n",
      "Epoch 197/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0619 - MAPE: 7.9013\n",
      "Epoch 198/200\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0758 - MAPE: 5.7219\n",
      "Epoch 199/200\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0669 - MAPE: 7.3078\n",
      "Epoch 200/200\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.0625 - MAPE: 7.4294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8d1029cbb0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=\"MAE\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.00001),\n",
    "    metrics=[\"MAPE\"],\n",
    ")\n",
    "\n",
    "model.fit([X_train,np.log(X_train_volume), np.log(X_train_area)], np.log(y_train), batch_size = 8, epochs = 200, verbose = 1)\n",
    "#model.fit([X_train,X_train_volume, X_train_area], np.log(y_train),validation_split = 0.2, batch_size = 8, epochs = 100, verbose = 1)\n",
    "#model.evaluate([X_test, np.log(X_test_volume),np.log(X_test_area)],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "id": "AVdZ5NrAMZGn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-03 21:38:03.739277: W tensorflow/core/common_runtime/bfc_allocator.cc:462] Allocator (GPU_0_bfc) ran out of memory trying to allocate 518.17MiB (rounded to 543338496)requested by op jjnet/conv3d_7/Conv3D\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-01-03 21:38:03.739465: I tensorflow/core/common_runtime/bfc_allocator.cc:1000] BFCAllocator dump for GPU_0_bfc\n",
      "2022-01-03 21:38:03.739485: I tensorflow/core/common_runtime/bfc_allocator.cc:1007] Bin (256): \tTotal Chunks: 147, Chunks in use: 147. 36.8KiB allocated for chunks. 36.8KiB in use in bin. 4.8KiB client-requested in use in bin.\n",
      "2022-01-03 21:38:03.739493: I tensorflow/core/common_runtime/bfc_allocator.cc:1007] Bin (512): \tTotal Chunks: 6, Chunks in use: 6. 4.5KiB allocated for chunks. 4.5KiB in use in bin. 3.5KiB client-requested in use in bin.\n",
      "2022-01-03 21:38:03.739502: I tensorflow/core/common_runtime/bfc_allocator.cc:1007] Bin (1024): \tTotal Chunks: 12, Chunks in use: 12. 15.0KiB allocated for chunks. 15.0KiB in use in bin. 14.4KiB client-requested in use in bin.\n",
      "2022-01-03 21:38:03.739510: I tensorflow/core/common_runtime/bfc_allocator.cc:1007] Bin (2048): \tTotal Chunks: 6, Chunks in use: 6. 19.5KiB allocated for chunks. 19.5KiB in use in bin. 18.0KiB client-requested in use in bin.\n",
      "2022-01-03 21:38:03.739518: I tensorflow/core/common_runtime/bfc_allocator.cc:1007] Bin (4096): \tTotal Chunks: 7, Chunks in use: 7. 47.0KiB allocated for chunks. 47.0KiB in use in bin. 43.9KiB client-requested in use in bin.\n",
      "2022-01-03 21:38:03.739527: I tensorflow/core/common_runtime/bfc_allocator.cc:1007] Bin (8192): \tTotal Chunks: 16, Chunks in use: 16. 183.5KiB allocated for chunks. 183.5KiB in use in bin. 171.2KiB client-requested in use in bin.\n",
      "2022-01-03 21:38:03.739536: I tensorflow/core/common_runtime/bfc_allocator.cc:1007] Bin (16384): \tTotal Chunks: 8, Chunks in use: 8. 200.2KiB allocated for chunks. 200.2KiB in use in bin. 189.0KiB client-requested in use in bin.\n",
      "2022-01-03 21:38:03.739544: I tensorflow/core/common_runtime/bfc_allocator.cc:1007] Bin (32768): \tTotal Chunks: 6, Chunks in use: 6. 330.2KiB allocated for chunks. 330.2KiB in use in bin. 324.0KiB client-requested in use in bin.\n",
      "2022-01-03 21:38:03.739551: I tensorflow/core/common_runtime/bfc_allocator.cc:1007] Bin (65536): \tTotal Chunks: 6, Chunks in use: 6. 648.0KiB allocated for chunks. 648.0KiB in use in bin. 648.0KiB client-requested in use in bin.\n",
      "2022-01-03 21:38:03.739559: I tensorflow/core/common_runtime/bfc_allocator.cc:1007] Bin (131072): \tTotal Chunks: 4, Chunks in use: 4. 760.2KiB allocated for chunks. 760.2KiB in use in bin. 703.1KiB client-requested in use in bin.\n",
      "2022-01-03 21:38:03.739567: I tensorflow/core/common_runtime/bfc_allocator.cc:1007] Bin (262144): \tTotal Chunks: 2, Chunks in use: 2. 530.8KiB allocated for chunks. 530.8KiB in use in bin. 351.6KiB client-requested in use in bin.\n",
      "2022-01-03 21:38:03.739574: I tensorflow/core/common_runtime/bfc_allocator.cc:1007] Bin (524288): \tTotal Chunks: 6, Chunks in use: 6. 3.02MiB allocated for chunks. 3.02MiB in use in bin. 3.02MiB client-requested in use in bin.\n",
      "2022-01-03 21:38:03.739581: I tensorflow/core/common_runtime/bfc_allocator.cc:1007] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-01-03 21:38:03.739588: I tensorflow/core/common_runtime/bfc_allocator.cc:1007] Bin (2097152): \tTotal Chunks: 4, Chunks in use: 4. 9.17MiB allocated for chunks. 9.17MiB in use in bin. 9.16MiB client-requested in use in bin.\n",
      "2022-01-03 21:38:03.739595: I tensorflow/core/common_runtime/bfc_allocator.cc:1007] Bin (4194304): \tTotal Chunks: 2, Chunks in use: 2. 8.15MiB allocated for chunks. 8.15MiB in use in bin. 4.58MiB client-requested in use in bin.\n",
      "2022-01-03 21:38:03.739601: I tensorflow/core/common_runtime/bfc_allocator.cc:1007] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-01-03 21:38:03.739607: I tensorflow/core/common_runtime/bfc_allocator.cc:1007] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-01-03 21:38:03.739615: I tensorflow/core/common_runtime/bfc_allocator.cc:1007] Bin (33554432): \tTotal Chunks: 2, Chunks in use: 1. 122.07MiB allocated for chunks. 61.04MiB in use in bin. 61.04MiB client-requested in use in bin.\n",
      "2022-01-03 21:38:03.739622: I tensorflow/core/common_runtime/bfc_allocator.cc:1007] Bin (67108864): \tTotal Chunks: 1, Chunks in use: 0. 125.77MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-01-03 21:38:03.739629: I tensorflow/core/common_runtime/bfc_allocator.cc:1007] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-01-03 21:38:03.739636: I tensorflow/core/common_runtime/bfc_allocator.cc:1007] Bin (268435456): \tTotal Chunks: 2, Chunks in use: 1. 974.92MiB allocated for chunks. 488.28MiB in use in bin. 488.28MiB client-requested in use in bin.\n",
      "2022-01-03 21:38:03.739647: I tensorflow/core/common_runtime/bfc_allocator.cc:1023] Bin for 518.17MiB was 256.00MiB, Chunk State: \n",
      "2022-01-03 21:38:03.739665: I tensorflow/core/common_runtime/bfc_allocator.cc:1029]   Size: 486.64MiB | Requested Size: 480B | in_use: 0 | bin_num: 20, prev:   Size: 256B | Requested Size: 4B | in_use: 1 | bin_num: -1, for: Cast, stepid: 17733498117515410176, last_action: 4470614410769684, for: UNUSED, stepid: 11093028398635939193, last_action: 4470614410769633\n",
      "2022-01-03 21:38:03.739671: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] Next region of size 1306329088\n",
      "2022-01-03 21:38:03.739684: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818000000 of size 1280 by op ScratchBuffer action_count 4470614405284096 step 0 next 1\n",
      "2022-01-03 21:38:03.739691: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818000500 of size 256 by op Fill action_count 4470614405284106 step 0 next 5\n",
      "2022-01-03 21:38:03.739697: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818000600 of size 256 by op Fill action_count 4470614405284107 step 0 next 8\n",
      "2022-01-03 21:38:03.739703: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818000700 of size 256 by op Sub action_count 4470614405284109 step 0 next 10\n",
      "2022-01-03 21:38:03.739709: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818000800 of size 256 by op Sub action_count 4470614405284110 step 0 next 11\n",
      "2022-01-03 21:38:03.739714: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818000900 of size 256 by op Fill action_count 4470614405284117 step 0 next 9\n",
      "2022-01-03 21:38:03.739720: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818000a00 of size 256 by op Sub action_count 4470614405284119 step 0 next 15\n",
      "2022-01-03 21:38:03.739725: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818000b00 of size 256 by op Sub action_count 4470614405284120 step 0 next 16\n",
      "2022-01-03 21:38:03.739731: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818000c00 of size 256 by op Fill action_count 4470614405284127 step 0 next 14\n",
      "2022-01-03 21:38:03.739736: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818000d00 of size 256 by op Sub action_count 4470614405284129 step 0 next 20\n",
      "2022-01-03 21:38:03.739742: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818000e00 of size 256 by op Sub action_count 4470614405284130 step 0 next 21\n",
      "2022-01-03 21:38:03.739747: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818000f00 of size 256 by op Fill action_count 4470614405284137 step 0 next 19\n",
      "2022-01-03 21:38:03.739752: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818001000 of size 256 by op Sub action_count 4470614405284139 step 0 next 24\n",
      "2022-01-03 21:38:03.739758: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818001100 of size 256 by op Sub action_count 4470614405284140 step 0 next 25\n",
      "2022-01-03 21:38:03.739763: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818001200 of size 256 by op Fill action_count 4470614405284147 step 0 next 2\n",
      "2022-01-03 21:38:03.739769: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818001300 of size 256 by op Sub action_count 4470614405284098 step 0 next 3\n",
      "2022-01-03 21:38:03.739774: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818001400 of size 256 by op Sub action_count 4470614405284099 step 0 next 4\n",
      "2022-01-03 21:38:03.739780: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818001500 of size 256 by op Sub action_count 4470614405284149 step 0 next 28\n",
      "2022-01-03 21:38:03.739785: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818001600 of size 256 by op Sub action_count 4470614405284150 step 0 next 29\n",
      "2022-01-03 21:38:03.739792: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818001700 of size 256 by op Fill action_count 4470614405284157 step 0 next 23\n",
      "2022-01-03 21:38:03.739797: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818001800 of size 256 by op Sub action_count 4470614405284159 step 0 next 32\n",
      "2022-01-03 21:38:03.739803: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818001900 of size 256 by op Sub action_count 4470614405284160 step 0 next 33\n",
      "2022-01-03 21:38:03.739808: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818001a00 of size 256 by op Sub action_count 4470614405284169 step 0 next 36\n",
      "2022-01-03 21:38:03.739814: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818001b00 of size 256 by op Sub action_count 4470614405284170 step 0 next 37\n",
      "2022-01-03 21:38:03.739819: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818001c00 of size 2048 by op Fill action_count 4470614405284177 step 0 next 6\n",
      "2022-01-03 21:38:03.739825: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818002400 of size 3584 by op Add action_count 4470614405284103 step 0 next 7\n",
      "2022-01-03 21:38:03.739831: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818003200 of size 27648 by op Add action_count 4470614405284134 step 0 next 22\n",
      "2022-01-03 21:38:03.739837: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818009e00 of size 256 by op Sub action_count 4470614405284189 step 0 next 44\n",
      "2022-01-03 21:38:03.739842: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818009f00 of size 256 by op Sub action_count 4470614405284190 step 0 next 45\n",
      "2022-01-03 21:38:03.739848: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281800a000 of size 256 by op Fill action_count 4470614405284197 step 0 next 46\n",
      "2022-01-03 21:38:03.739853: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281800a100 of size 256 by op Fill action_count 4470614405284207 step 0 next 52\n",
      "2022-01-03 21:38:03.739858: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281800a200 of size 256 by op Fill action_count 4470614405284217 step 0 next 55\n",
      "2022-01-03 21:38:03.739864: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281800a300 of size 256 by op Sub action_count 4470614405284209 step 0 next 56\n",
      "2022-01-03 21:38:03.739869: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281800a400 of size 256 by op Sub action_count 4470614405284210 step 0 next 57\n",
      "2022-01-03 21:38:03.739875: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281800a500 of size 256 by op Add action_count 4470614405284214 step 0 next 49\n",
      "2022-01-03 21:38:03.739880: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281800a600 of size 256 by op Sub action_count 4470614405284199 step 0 next 50\n",
      "2022-01-03 21:38:03.739886: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281800a700 of size 256 by op Sub action_count 4470614405284200 step 0 next 51\n",
      "2022-01-03 21:38:03.739891: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281800a800 of size 256 by op AssignVariableOp action_count 4470614405284218 step 0 next 58\n",
      "2022-01-03 21:38:03.739897: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281800a900 of size 256 by op Fill action_count 4470614405284219 step 0 next 59\n",
      "2022-01-03 21:38:03.739902: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281800aa00 of size 256 by op Fill action_count 4470614405284220 step 0 next 60\n",
      "2022-01-03 21:38:03.739908: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281800ab00 of size 256 by op AssignVariableOp action_count 4470614405284221 step 0 next 61\n",
      "2022-01-03 21:38:03.739913: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281800ac00 of size 256 by op Fill action_count 4470614405284222 step 0 next 62\n",
      "2022-01-03 21:38:03.739920: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281800ad00 of size 256 by op AssignVariableOp action_count 4470614405284223 step 0 next 53\n",
      "2022-01-03 21:38:03.739926: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281800ae00 of size 1280 by op Add action_count 4470614405284204 step 0 next 54\n",
      "2022-01-03 21:38:03.739931: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281800b300 of size 256 by op AssignVariableOp action_count 4470614405284224 step 0 next 63\n",
      "2022-01-03 21:38:03.739937: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281800b400 of size 256 by op AssignVariableOp action_count 4470614405284225 step 0 next 64\n",
      "2022-01-03 21:38:03.739942: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281800b500 of size 256 by op AssignVariableOp action_count 4470614405284226 step 0 next 65\n",
      "2022-01-03 21:38:03.739947: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281800b600 of size 256 by op Fill action_count 4470614405284227 step 0 next 66\n",
      "2022-01-03 21:38:03.739954: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281800b700 of size 6400 by op Fill action_count 4470614405284228 step 0 next 47\n",
      "2022-01-03 21:38:03.739959: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281800d000 of size 12032 by op Add action_count 4470614405284194 step 0 next 48\n",
      "2022-01-03 21:38:03.739965: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281800ff00 of size 58112 by op Fill action_count 4470614405284232 step 0 next 18\n",
      "2022-01-03 21:38:03.739971: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281801e200 of size 55296 by op Add action_count 4470614405284124 step 0 next 17\n",
      "2022-01-03 21:38:03.739977: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281802ba00 of size 6912 by op Add action_count 4470614405284154 step 0 next 30\n",
      "2022-01-03 21:38:03.739983: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281802d500 of size 256 by op Sub action_count 4470614405284179 step 0 next 40\n",
      "2022-01-03 21:38:03.739988: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281802d600 of size 256 by op Sub action_count 4470614405284180 step 0 next 41\n",
      "2022-01-03 21:38:03.739994: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281802d700 of size 768 by op Fill action_count 4470614405284187 step 0 next 31\n",
      "2022-01-03 21:38:03.739999: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281802da00 of size 256 by op Fill action_count 4470614405284229 step 0 next 67\n",
      "2022-01-03 21:38:03.740004: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281802db00 of size 256 by op Fill action_count 4470614405284231 step 0 next 69\n",
      "2022-01-03 21:38:03.740010: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281802dc00 of size 256 by op Fill action_count 4470614405284233 step 0 next 70\n",
      "2022-01-03 21:38:03.740015: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281802dd00 of size 256 by op Fill action_count 4470614405284235 step 0 next 72\n",
      "2022-01-03 21:38:03.740021: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281802de00 of size 18432 by op Fill action_count 4470614405284236 step 0 next 26\n",
      "2022-01-03 21:38:03.740027: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818032600 of size 13824 by op Add action_count 4470614405284144 step 0 next 27\n",
      "2022-01-03 21:38:03.740032: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818035c00 of size 13824 by op Fill action_count 4470614405284167 step 0 next 13\n",
      "2022-01-03 21:38:03.740038: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818039200 of size 110592 by op Add action_count 4470614405284114 step 0 next 12\n",
      "2022-01-03 21:38:03.740043: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818054200 of size 110592 by op Fill action_count 4470614405284230 step 0 next 68\n",
      "2022-01-03 21:38:03.740050: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281806f200 of size 27648 by op Fill action_count 4470614405284234 step 0 next 71\n",
      "2022-01-03 21:38:03.740055: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818075e00 of size 256 by op Fill action_count 4470614405284237 step 0 next 73\n",
      "2022-01-03 21:38:03.740061: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818075f00 of size 6912 by op Fill action_count 4470614405284238 step 0 next 74\n",
      "2022-01-03 21:38:03.740066: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818077a00 of size 256 by op Fill action_count 4470614405284239 step 0 next 75\n",
      "2022-01-03 21:38:03.740072: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818077b00 of size 8192 by op Fill action_count 4470614405284241 step 0 next 77\n",
      "2022-01-03 21:38:03.740077: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818079b00 of size 1280 by op Fill action_count 4470614405284243 step 0 next 78\n",
      "2022-01-03 21:38:03.740083: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281807a000 of size 205312 by op Fill action_count 4470614405284244 step 0 next 43\n",
      "2022-01-03 21:38:03.740089: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f28180ac200 of size 180224 by op Add action_count 4470614405284184 step 0 next 42\n",
      "2022-01-03 21:38:03.740094: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f28180d8200 of size 768 by op Fill action_count 4470614405284245 step 0 next 79\n",
      "2022-01-03 21:38:03.740123: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f28180d8500 of size 12032 by op Fill action_count 4470614405284246 step 0 next 80\n",
      "2022-01-03 21:38:03.740129: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f28180db400 of size 256 by op Fill action_count 4470614405284247 step 0 next 81\n",
      "2022-01-03 21:38:03.740278: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f28180db500 of size 1280 by op Fill action_count 4470614405284248 step 0 next 82\n",
      "2022-01-03 21:38:03.740330: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f28180dba00 of size 256 by op Fill action_count 4470614405284249 step 0 next 83\n",
      "2022-01-03 21:38:03.740349: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f28180dbb00 of size 256 by op Fill action_count 4470614405284250 step 0 next 84\n",
      "2022-01-03 21:38:03.740367: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f28180dbc00 of size 256 by op Fill action_count 4470614405284251 step 0 next 85\n",
      "2022-01-03 21:38:03.740384: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f28180dbd00 of size 3584 by op Fill action_count 4470614405284252 step 0 next 86\n",
      "2022-01-03 21:38:03.740402: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f28180dcb00 of size 256 by op Fill action_count 4470614405284253 step 0 next 87\n",
      "2022-01-03 21:38:03.740419: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f28180dcc00 of size 110592 by op Fill action_count 4470614405284254 step 0 next 88\n",
      "2022-01-03 21:38:03.740436: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f28180f7c00 of size 256 by op Fill action_count 4470614405284255 step 0 next 89\n",
      "2022-01-03 21:38:03.740454: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f28180f7d00 of size 55296 by op Fill action_count 4470614405284256 step 0 next 90\n",
      "2022-01-03 21:38:03.740470: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818105500 of size 256 by op Fill action_count 4470614405284257 step 0 next 91\n",
      "2022-01-03 21:38:03.740487: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818105600 of size 27648 by op Fill action_count 4470614405284258 step 0 next 92\n",
      "2022-01-03 21:38:03.740504: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281810c200 of size 256 by op Fill action_count 4470614405284259 step 0 next 93\n",
      "2022-01-03 21:38:03.740527: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281810c300 of size 13824 by op Fill action_count 4470614405284260 step 0 next 94\n",
      "2022-01-03 21:38:03.740545: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281810f900 of size 256 by op Fill action_count 4470614405284261 step 0 next 95\n",
      "2022-01-03 21:38:03.740560: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281810fa00 of size 6912 by op Fill action_count 4470614405284262 step 0 next 96\n",
      "2022-01-03 21:38:03.740576: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818111500 of size 256 by op Fill action_count 4470614405284263 step 0 next 97\n",
      "2022-01-03 21:38:03.740591: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818111600 of size 8192 by op Fill action_count 4470614405284265 step 0 next 99\n",
      "2022-01-03 21:38:03.740606: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818113600 of size 1280 by op Fill action_count 4470614405284267 step 0 next 101\n",
      "2022-01-03 21:38:03.740624: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818113b00 of size 271616 by op Fill action_count 4470614405284268 step 0 next 35\n",
      "2022-01-03 21:38:03.740641: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818156000 of size 528128 by op Add action_count 4470614405284164 step 0 next 34\n",
      "2022-01-03 21:38:03.740656: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f28181d6f00 of size 528128 by op Fill action_count 4470614405284240 step 0 next 76\n",
      "2022-01-03 21:38:03.740672: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818257e00 of size 4271872 by op Fill action_count 4470614405284242 step 0 next 39\n",
      "2022-01-03 21:38:03.740689: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281866ad00 of size 2400000 by op Add action_count 4470614405284174 step 0 next 38\n",
      "2022-01-03 21:38:03.740704: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f28188b4c00 of size 528128 by op Fill action_count 4470614405284264 step 0 next 98\n",
      "2022-01-03 21:38:03.740719: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818935b00 of size 2400000 by op Fill action_count 4470614405284266 step 0 next 100\n",
      "2022-01-03 21:38:03.740734: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b7fa00 of size 768 by op Fill action_count 4470614405284269 step 0 next 102\n",
      "2022-01-03 21:38:03.740749: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b7fd00 of size 12032 by op Fill action_count 4470614405284270 step 0 next 103\n",
      "2022-01-03 21:38:03.740764: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b82c00 of size 256 by op Fill action_count 4470614405284271 step 0 next 104\n",
      "2022-01-03 21:38:03.740779: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b82d00 of size 1280 by op Fill action_count 4470614405284272 step 0 next 105\n",
      "2022-01-03 21:38:03.740794: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b83200 of size 256 by op Fill action_count 4470614405284273 step 0 next 106\n",
      "2022-01-03 21:38:03.740809: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b83300 of size 256 by op Fill action_count 4470614405284274 step 0 next 107\n",
      "2022-01-03 21:38:03.740824: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b83400 of size 256 by op Fill action_count 4470614405284275 step 0 next 108\n",
      "2022-01-03 21:38:03.740839: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b83500 of size 256 by op Fill action_count 4470614405284276 step 0 next 109\n",
      "2022-01-03 21:38:03.740854: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b83600 of size 256 by op Fill action_count 4470614405284277 step 0 next 110\n",
      "2022-01-03 21:38:03.740869: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b83700 of size 256 by op Sum_1 action_count 4470614405284278 step 0 next 111\n",
      "2022-01-03 21:38:03.740887: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b83800 of size 256 by op Adam/add/y action_count 4470614405284279 step 0 next 112\n",
      "2022-01-03 21:38:03.740903: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b83900 of size 256 by op gradient_tape/mean_absolute_error/truediv action_count 4470614405284280 step 0 next 113\n",
      "2022-01-03 21:38:03.740919: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b83a00 of size 256 by op jjnet/dropout/dropout/Const action_count 4470614405284281 step 0 next 114\n",
      "2022-01-03 21:38:03.740934: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b83b00 of size 256 by op jjnet/dropout/dropout/GreaterEqual/y action_count 4470614405284282 step 0 next 115\n",
      "2022-01-03 21:38:03.740949: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b83c00 of size 256 by op Adam/Const action_count 4470614405284283 step 0 next 116\n",
      "2022-01-03 21:38:03.740965: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b83d00 of size 256 by op mul_1/x action_count 4470614405284284 step 0 next 117\n",
      "2022-01-03 21:38:03.740980: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b83e00 of size 256 by op Const_1 action_count 4470614405284285 step 0 next 118\n",
      "2022-01-03 21:38:03.740995: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b83f00 of size 256 by op Adam/Adam/Const action_count 4470614405284286 step 0 next 119\n",
      "2022-01-03 21:38:03.741010: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b84000 of size 256 by op Fill action_count 4470614405284346 step 0 next 131\n",
      "2022-01-03 21:38:03.741025: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b84100 of size 256 by op Fill action_count 4470614405284354 step 0 next 129\n",
      "2022-01-03 21:38:03.741041: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b84200 of size 256 by op Fill action_count 4470614405284362 step 0 next 122\n",
      "2022-01-03 21:38:03.741056: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b84300 of size 256 by op Fill action_count 4470614405284370 step 0 next 120\n",
      "2022-01-03 21:38:03.741071: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b84400 of size 256 by op Fill action_count 4470614405284378 step 0 next 125\n",
      "2022-01-03 21:38:03.741086: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b84500 of size 256 by op Fill action_count 4470614405284386 step 0 next 128\n",
      "2022-01-03 21:38:03.741101: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b84600 of size 1280 by op Fill action_count 4470614405284402 step 0 next 136\n",
      "2022-01-03 21:38:03.741116: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b84b00 of size 768 by op Fill action_count 4470614405284410 step 0 next 141\n",
      "2022-01-03 21:38:03.741131: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b84e00 of size 256 by op Fill action_count 4470614405284418 step 0 next 146\n",
      "2022-01-03 21:38:03.741146: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b84f00 of size 256 by op Fill action_count 4470614405284426 step 0 next 147\n",
      "2022-01-03 21:38:03.741161: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b85000 of size 256 by op Fill action_count 4470614405284434 step 0 next 148\n",
      "2022-01-03 21:38:03.741176: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b85100 of size 256 by op Add action_count 4470614405284431 step 0 next 150\n",
      "2022-01-03 21:38:03.741191: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b85200 of size 256 by op Const action_count 4470614408027148 step 0 next 229\n",
      "2022-01-03 21:38:03.741206: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b85300 of size 256 by op AssignVariableOp action_count 4470614408026889 step 0 next 152\n",
      "2022-01-03 21:38:03.741221: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b85400 of size 256 by op AssignVariableOp action_count 4470614410769663 step 0 next 153\n",
      "2022-01-03 21:38:03.741237: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b85500 of size 256 by op Fill action_count 4470614408027406 step 0 next 209\n",
      "2022-01-03 21:38:03.741251: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b85600 of size 256 by op Fill action_count 4470614408027408 step 0 next 154\n",
      "2022-01-03 21:38:03.741265: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b85700 of size 256 by op Fill action_count 4470614408027410 step 0 next 156\n",
      "2022-01-03 21:38:03.741280: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b85800 of size 256 by op Fill action_count 4470614408027412 step 0 next 157\n",
      "2022-01-03 21:38:03.741295: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b85900 of size 256 by op Fill action_count 4470614408027414 step 0 next 159\n",
      "2022-01-03 21:38:03.741310: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b85a00 of size 256 by op Fill action_count 4470614408027416 step 0 next 160\n",
      "2022-01-03 21:38:03.741325: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b85b00 of size 256 by op Fill action_count 4470614408027418 step 0 next 161\n",
      "2022-01-03 21:38:03.741339: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b85c00 of size 256 by op Fill action_count 4470614408027426 step 0 next 126\n",
      "2022-01-03 21:38:03.741355: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b85d00 of size 3584 by op Add action_count 4470614405284343 step 0 next 127\n",
      "2022-01-03 21:38:03.741370: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b86b00 of size 27648 by op Add action_count 4470614405284367 step 0 next 133\n",
      "2022-01-03 21:38:03.741385: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b8d700 of size 1280 by op Add action_count 4470614405284423 step 0 next 149\n",
      "2022-01-03 21:38:03.741400: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b8dc00 of size 3584 by op Fill action_count 4470614408027407 step 0 next 241\n",
      "2022-01-03 21:38:03.741416: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b8ea00 of size 7168 by op Fill action_count 4470614408027417 step 0 next 145\n",
      "2022-01-03 21:38:03.741431: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b90600 of size 12032 by op Add action_count 4470614405284415 step 0 next 144\n",
      "2022-01-03 21:38:03.741446: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818b93500 of size 58880 by op Fill action_count 4470614408027411 step 0 next 124\n",
      "2022-01-03 21:38:03.741461: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818ba1b00 of size 55296 by op Add action_count 4470614405284359 step 0 next 123\n",
      "2022-01-03 21:38:03.741476: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818baf300 of size 6912 by op Add action_count 4470614405284383 step 0 next 135\n",
      "2022-01-03 21:38:03.741491: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818bb0e00 of size 20736 by op Fill action_count 4470614408027415 step 0 next 134\n",
      "2022-01-03 21:38:03.741507: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818bb5f00 of size 13824 by op Add action_count 4470614405284375 step 0 next 132\n",
      "2022-01-03 21:38:03.741522: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818bb9500 of size 13824 by op Fill action_count 4470614405284394 step 0 next 121\n",
      "2022-01-03 21:38:03.741536: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818bbcb00 of size 110592 by op Add action_count 4470614405284351 step 0 next 130\n",
      "2022-01-03 21:38:03.741551: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818bd7b00 of size 110592 by op Fill action_count 4470614408027409 step 0 next 155\n",
      "2022-01-03 21:38:03.741566: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818bf2b00 of size 27648 by op Fill action_count 4470614408027413 step 0 next 158\n",
      "2022-01-03 21:38:03.741581: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818bf9700 of size 8192 by op Fill action_count 4470614408027420 step 0 next 163\n",
      "2022-01-03 21:38:03.741596: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818bfb700 of size 1280 by op Fill action_count 4470614408027422 step 0 next 164\n",
      "2022-01-03 21:38:03.741611: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818bfbc00 of size 212736 by op Fill action_count 4470614408027423 step 0 next 143\n",
      "2022-01-03 21:38:03.741626: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818c2fb00 of size 180224 by op Add action_count 4470614405284407 step 0 next 142\n",
      "2022-01-03 21:38:03.741641: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818c5bb00 of size 768 by op Fill action_count 4470614408027424 step 0 next 165\n",
      "2022-01-03 21:38:03.741655: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818c5be00 of size 12032 by op Fill action_count 4470614408027425 step 0 next 166\n",
      "2022-01-03 21:38:03.741670: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818c5ed00 of size 1280 by op Fill action_count 4470614408027427 step 0 next 167\n",
      "2022-01-03 21:38:03.741684: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818c5f200 of size 256 by op Fill action_count 4470614408027428 step 0 next 168\n",
      "2022-01-03 21:38:03.741699: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818c5f300 of size 256 by op Fill action_count 4470614408027429 step 0 next 169\n",
      "2022-01-03 21:38:03.741714: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818c5f400 of size 256 by op Fill action_count 4470614408027430 step 0 next 170\n",
      "2022-01-03 21:38:03.741729: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818c5f500 of size 3584 by op Fill action_count 4470614408027431 step 0 next 171\n",
      "2022-01-03 21:38:03.741744: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818c60300 of size 256 by op Fill action_count 4470614408027432 step 0 next 172\n",
      "2022-01-03 21:38:03.741758: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818c60400 of size 110592 by op Fill action_count 4470614408027433 step 0 next 173\n",
      "2022-01-03 21:38:03.741773: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818c7b400 of size 256 by op Fill action_count 4470614408027434 step 0 next 174\n",
      "2022-01-03 21:38:03.741788: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818c7b500 of size 55296 by op Fill action_count 4470614408027435 step 0 next 175\n",
      "2022-01-03 21:38:03.741803: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818c88d00 of size 256 by op Fill action_count 4470614408027436 step 0 next 176\n",
      "2022-01-03 21:38:03.741818: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818c88e00 of size 27648 by op Fill action_count 4470614408027437 step 0 next 177\n",
      "2022-01-03 21:38:03.741832: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818c8fa00 of size 256 by op Fill action_count 4470614408027438 step 0 next 178\n",
      "2022-01-03 21:38:03.741846: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818c8fb00 of size 13824 by op Fill action_count 4470614408027439 step 0 next 179\n",
      "2022-01-03 21:38:03.741861: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818c93100 of size 256 by op Fill action_count 4470614408027440 step 0 next 180\n",
      "2022-01-03 21:38:03.741875: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818c93200 of size 6912 by op Fill action_count 4470614408027441 step 0 next 181\n",
      "2022-01-03 21:38:03.741889: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818c94d00 of size 256 by op Fill action_count 4470614408027442 step 0 next 182\n",
      "2022-01-03 21:38:03.741906: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818c94e00 of size 8192 by op Fill action_count 4470614408027444 step 0 next 184\n",
      "2022-01-03 21:38:03.741921: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818c96e00 of size 1280 by op Fill action_count 4470614408027446 step 0 next 185\n",
      "2022-01-03 21:38:03.741936: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818c97300 of size 271872 by op Fill action_count 4470614408027447 step 0 next 138\n",
      "2022-01-03 21:38:03.741951: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818cd9900 of size 528128 by op Add action_count 4470614405284391 step 0 next 137\n",
      "2022-01-03 21:38:03.741965: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818d5a800 of size 528128 by op Fill action_count 4470614408027443 step 0 next 183\n",
      "2022-01-03 21:38:03.741980: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2818ddb700 of size 4271872 by op Fill action_count 4470614408027445 step 0 next 140\n",
      "2022-01-03 21:38:03.741995: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f28191ee600 of size 2400000 by op Add action_count 4470614405284399 step 0 next 139\n",
      "2022-01-03 21:38:03.742011: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2819438500 of size 528128 by op Fill action_count 4470614408027419 step 0 next 162\n",
      "2022-01-03 21:38:03.742026: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f28194b9400 of size 2415104 by op Fill action_count 4470614408027421 step 0 next 194\n",
      "2022-01-03 21:38:03.742042: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2819706e00 of size 256 by op AssignVariableOp action_count 4470614408026891 step 0 next 195\n",
      "2022-01-03 21:38:03.742057: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2819706f00 of size 256 by op Maximum/y action_count 4470614405309844 step 0 next 196\n",
      "2022-01-03 21:38:03.742072: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2819707000 of size 256 by op Sum_1 action_count 4470614405284488 step 0 next 197\n",
      "2022-01-03 21:38:03.742086: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2819707100 of size 256 by op Adam/add/y action_count 4470614405284489 step 0 next 198\n",
      "2022-01-03 21:38:03.742101: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2819707200 of size 256 by op gradient_tape/mean_absolute_error/truediv action_count 4470614405284490 step 0 next 199\n",
      "2022-01-03 21:38:03.742116: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2819707300 of size 256 by op jjnet/dropout_3/dropout/Const action_count 4470614405284491 step 0 next 200\n",
      "2022-01-03 21:38:03.742131: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2819707400 of size 256 by op jjnet/dropout_3/dropout/GreaterEqual/y action_count 4470614405284492 step 0 next 201\n",
      "2022-01-03 21:38:03.742146: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2819707500 of size 256 by op Adam/Const action_count 4470614405284493 step 0 next 202\n",
      "2022-01-03 21:38:03.742161: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2819707600 of size 256 by op mul_1/x action_count 4470614405284494 step 0 next 203\n",
      "2022-01-03 21:38:03.742175: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2819707700 of size 256 by op Const_1 action_count 4470614405284495 step 0 next 204\n",
      "2022-01-03 21:38:03.742190: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2819707800 of size 256 by op Adam/Adam/Const action_count 4470614405284496 step 0 next 205\n",
      "2022-01-03 21:38:03.742205: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2819707900 of size 256 by op AssignVariableOp action_count 4470614408026887 step 0 next 228\n",
      "2022-01-03 21:38:03.742220: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2819707a00 of size 256 by op mul_1/x action_count 4470614405309845 step 0 next 250\n",
      "2022-01-03 21:38:03.742235: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2819707b00 of size 256 by op Const_1 action_count 4470614405309846 step 0 next 219\n",
      "2022-01-03 21:38:03.742250: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2819707c00 of size 256 by op AssignVariableOp action_count 4470614408026885 step 0 next 221\n",
      "2022-01-03 21:38:03.742264: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2819707d00 of size 256 by op AssignVariableOp action_count 4470614410769665 step 0 next 213\n",
      "2022-01-03 21:38:03.742278: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2819707e00 of size 256 by op AssignVariableOp action_count 4470614410769667 step 0 next 212\n",
      "2022-01-03 21:38:03.742293: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2819707f00 of size 256 by op AssignAddVariableOp action_count 4470614408027260 step 17212556612637707062 next 257\n",
      "2022-01-03 21:38:03.742307: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2819708000 of size 768 by op Fill action_count 4470614408027448 step 0 next 186\n",
      "2022-01-03 21:38:03.742322: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f2819708300 of size 12032 by op Fill action_count 4470614408027449 step 0 next 187\n",
      "2022-01-03 21:38:03.742336: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281970b200 of size 256 by op Fill action_count 4470614408027450 step 0 next 188\n",
      "2022-01-03 21:38:03.742351: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281970b300 of size 1280 by op Fill action_count 4470614408027451 step 0 next 189\n",
      "2022-01-03 21:38:03.742365: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281970b800 of size 256 by op Fill action_count 4470614408027452 step 0 next 190\n",
      "2022-01-03 21:38:03.742380: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281970b900 of size 256 by op Fill action_count 4470614408027453 step 0 next 191\n",
      "2022-01-03 21:38:03.742395: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281970ba00 of size 256 by op Fill action_count 4470614408027454 step 0 next 192\n",
      "2022-01-03 21:38:03.742410: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281970bb00 of size 256 by op AssignVariableOp action_count 4470614410769669 step 0 next 193\n",
      "2022-01-03 21:38:03.742425: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281970bc00 of size 256 by op Maximum/y action_count 4470614408052674 step 0 next 223\n",
      "2022-01-03 21:38:03.742441: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281970bd00 of size 256 by op Sum_1 action_count 4470614408027457 step 0 next 237\n",
      "2022-01-03 21:38:03.742456: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281970be00 of size 256 by op Adam/add/y action_count 4470614408027458 step 0 next 254\n",
      "2022-01-03 21:38:03.742472: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281970bf00 of size 256 by op gradient_tape/mean_absolute_error/truediv action_count 4470614408027459 step 0 next 227\n",
      "2022-01-03 21:38:03.742487: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281970c000 of size 256 by op jjnet/dropout_3/dropout/Const action_count 4470614408027460 step 0 next 234\n",
      "2022-01-03 21:38:03.742503: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281970c100 of size 256 by op jjnet/dropout_3/dropout/GreaterEqual/y action_count 4470614408027461 step 0 next 211\n",
      "2022-01-03 21:38:03.742517: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281970c200 of size 256 by op Adam/Const action_count 4470614408027462 step 0 next 210\n",
      "2022-01-03 21:38:03.742533: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281970c300 of size 256 by op mul_1/x action_count 4470614408027463 step 0 next 258\n",
      "2022-01-03 21:38:03.742548: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281970c400 of size 256 by op Const_1 action_count 4470614408027464 step 0 next 231\n",
      "2022-01-03 21:38:03.742564: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281970c500 of size 256 by op Adam/Adam/Const action_count 4470614408027465 step 0 next 220\n",
      "2022-01-03 21:38:03.742579: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281970c600 of size 256 by op SameWorkerRecvDone action_count 4470614410769671 step 0 next 262\n",
      "2022-01-03 21:38:03.742595: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281970c700 of size 256 by op AssignAddVariableOp_4 action_count 4470614408027629 step 10575140908241313233 next 217\n",
      "2022-01-03 21:38:03.742610: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281970c800 of size 256 by op mul_1/x action_count 4470614408052675 step 0 next 266\n",
      "2022-01-03 21:38:03.742625: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281970c900 of size 256 by op SameWorkerRecvDone action_count 4470614410769672 step 0 next 260\n",
      "2022-01-03 21:38:03.742640: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281970ca00 of size 256 by op Const_1 action_count 4470614408052676 step 0 next 216\n",
      "2022-01-03 21:38:03.742657: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f281970cb00 of size 64000000 by op jjnet/conv3d_7/Conv3D action_count 4470614410769683 step 17733498117515410176 next 274\n",
      "2022-01-03 21:38:03.742673: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] Free  at 7f281d415b00 of size 64000000 by op UNUSED action_count 4470614410769651 step 11093028398635939193 next 207\n",
      "2022-01-03 21:38:03.742688: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f282111eb00 of size 256 by op SameWorkerRecvDone action_count 4470614410769674 step 0 next 151\n",
      "2022-01-03 21:38:03.742705: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f282111ec00 of size 512000000 by op jjnet/conv3d_6/Conv3D action_count 4470614410769675 step 17733498117515410176 next 242\n",
      "2022-01-03 21:38:03.742720: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] Free  at 7f283f966c00 of size 131878656 by op UNUSED action_count 4470614410769681 step 17733498117515410176 next 248\n",
      "2022-01-03 21:38:03.742737: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f284772bb00 of size 256 by op Abs action_count 4470614410769677 step 17733498117515410176 next 259\n",
      "2022-01-03 21:38:03.742752: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] InUse at 7f284772bc00 of size 256 by op Cast action_count 4470614410769684 step 17733498117515410176 next 261\n",
      "2022-01-03 21:38:03.742768: I tensorflow/core/common_runtime/bfc_allocator.cc:1055] Free  at 7f284772bd00 of size 510280448 by op UNUSED action_count 4470614410769633 step 11093028398635939193 next 18446744073709551615\n",
      "2022-01-03 21:38:03.742782: I tensorflow/core/common_runtime/bfc_allocator.cc:1060]      Summary of in-use Chunks by size: \n",
      "2022-01-03 21:38:03.742810: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 147 Chunks of size 256 totalling 36.8KiB\n",
      "2022-01-03 21:38:03.742828: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 6 Chunks of size 768 totalling 4.5KiB\n",
      "2022-01-03 21:38:03.742845: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 12 Chunks of size 1280 totalling 15.0KiB\n",
      "2022-01-03 21:38:03.742862: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 1 Chunks of size 2048 totalling 2.0KiB\n",
      "2022-01-03 21:38:03.742879: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 5 Chunks of size 3584 totalling 17.5KiB\n",
      "2022-01-03 21:38:03.742895: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 1 Chunks of size 6400 totalling 6.2KiB\n",
      "2022-01-03 21:38:03.742913: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 5 Chunks of size 6912 totalling 33.8KiB\n",
      "2022-01-03 21:38:03.742929: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 1 Chunks of size 7168 totalling 7.0KiB\n",
      "2022-01-03 21:38:03.742946: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 4 Chunks of size 8192 totalling 32.0KiB\n",
      "2022-01-03 21:38:03.742965: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 6 Chunks of size 12032 totalling 70.5KiB\n",
      "2022-01-03 21:38:03.742982: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 6 Chunks of size 13824 totalling 81.0KiB\n",
      "2022-01-03 21:38:03.742999: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 1 Chunks of size 18432 totalling 18.0KiB\n",
      "2022-01-03 21:38:03.743016: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 1 Chunks of size 20736 totalling 20.2KiB\n",
      "2022-01-03 21:38:03.743033: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 6 Chunks of size 27648 totalling 162.0KiB\n",
      "2022-01-03 21:38:03.743049: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 4 Chunks of size 55296 totalling 216.0KiB\n",
      "2022-01-03 21:38:03.743066: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 1 Chunks of size 58112 totalling 56.8KiB\n",
      "2022-01-03 21:38:03.743083: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 1 Chunks of size 58880 totalling 57.5KiB\n",
      "2022-01-03 21:38:03.743101: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 6 Chunks of size 110592 totalling 648.0KiB\n",
      "2022-01-03 21:38:03.743118: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 2 Chunks of size 180224 totalling 352.0KiB\n",
      "2022-01-03 21:38:03.743134: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 1 Chunks of size 205312 totalling 200.5KiB\n",
      "2022-01-03 21:38:03.743151: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 1 Chunks of size 212736 totalling 207.8KiB\n",
      "2022-01-03 21:38:03.743169: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 1 Chunks of size 271616 totalling 265.2KiB\n",
      "2022-01-03 21:38:03.743185: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 1 Chunks of size 271872 totalling 265.5KiB\n",
      "2022-01-03 21:38:03.743202: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 6 Chunks of size 528128 totalling 3.02MiB\n",
      "2022-01-03 21:38:03.743218: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 3 Chunks of size 2400000 totalling 6.87MiB\n",
      "2022-01-03 21:38:03.743235: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 1 Chunks of size 2415104 totalling 2.30MiB\n",
      "2022-01-03 21:38:03.743251: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 2 Chunks of size 4271872 totalling 8.15MiB\n",
      "2022-01-03 21:38:03.743268: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 1 Chunks of size 64000000 totalling 61.04MiB\n",
      "2022-01-03 21:38:03.743285: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] 1 Chunks of size 512000000 totalling 488.28MiB\n",
      "2022-01-03 21:38:03.743303: I tensorflow/core/common_runtime/bfc_allocator.cc:1067] Sum Total of in-use chunks: 572.37MiB\n",
      "2022-01-03 21:38:03.743318: I tensorflow/core/common_runtime/bfc_allocator.cc:1069] total_region_allocated_bytes_: 1306329088 memory_limit_: 1306329088 available bytes: 0 curr_region_allocation_bytes_: 2612658176\n",
      "2022-01-03 21:38:03.743341: I tensorflow/core/common_runtime/bfc_allocator.cc:1075] Stats: \n",
      "Limit:                      1306329088\n",
      "InUse:                       600169984\n",
      "MaxInUse:                   1242329088\n",
      "NumAllocs:                     2742912\n",
      "MaxAllocSize:                610180352\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-01-03 21:38:03.743389: W tensorflow/core/common_runtime/bfc_allocator.cc:473] *******____****************************************_________*_______________________________________\n",
      "2022-01-03 21:38:03.743811: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_ops_3d.cc:458 : Resource exhausted: OOM when allocating tensor with shape[32,32,51,51,51] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[32,32,51,51,51] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node jjnet/conv3d_7/Conv3D (defined at tmp/ipykernel_49319/1886996265.py:7) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_test_function_25072]\n\nFunction call stack:\ntest_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_49319/677321760.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_volume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_area\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1487\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1489\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1490\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[32,32,51,51,51] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node jjnet/conv3d_7/Conv3D (defined at tmp/ipykernel_49319/1886996265.py:7) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_test_function_25072]\n\nFunction call stack:\ntest_function\n"
     ]
    }
   ],
   "source": [
    "model.evaluate([X_test, np.log(X_test_volume),np.log(X_test_area)],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "2SBZORUO_5vT",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds = model.predict([X_test, np.log(X_test_volume),np.log(X_test_area)])#*y_train_max\n",
    "#preds = model.predict([X_test,X_test_volume,X_test_area])#*y_train_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BfttA-O3EyJH",
    "outputId": "92157cb2-8752-4dfa-9c1e-f142d201be63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1704.2304685959189 63.12668178023365\n"
     ]
    }
   ],
   "source": [
    "#mae\n",
    "print(np.sum(abs(np.exp(preds)-(y_test)))/len(preds),np.sum(abs(((preds)-(np.log(y_test)))))/len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UMd33s76GSXX",
    "outputId": "64266694-429b-40ef-fabb-57ba36b69ee6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341.2339792734442"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MAPE\n",
    "np.sum(abs((np.exp(preds)-(y_test))/(y_test)))/len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fO-njwLL3Vpl",
    "outputId": "8208367e-5e57-48cc-88eb-cf8927dfc2de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predikcija 3.18  Cena  2.6\n",
      "Predikcija 41.08  Cena  38.24\n",
      "Predikcija 7.2  Cena  5.34\n",
      "Predikcija 11.6  Cena  9.56\n",
      "Predikcija 68.64  Cena  90.1\n",
      "Predikcija 19.8  Cena  11.34\n",
      "Predikcija 9.83  Cena  8.12\n",
      "Predikcija 2.08  Cena  1.99\n",
      "Predikcija 15.96  Cena  14.89\n",
      "Predikcija 13.4  Cena  8.58\n",
      "Predikcija 18.1  Cena  16.09\n",
      "Predikcija 43.98  Cena  36.27\n",
      "Predikcija 4.4  Cena  1.76\n",
      "Predikcija 14.43  Cena  6.81\n",
      "Predikcija 15.02  Cena  9.04\n",
      "Predikcija 11.17  Cena  10.26\n",
      "Predikcija 68.8  Cena  126.5\n",
      "Predikcija 73.0  Cena  66.36\n",
      "Predikcija 13.89  Cena  14.33\n",
      "Predikcija 46.43  Cena  38.22\n",
      "Predikcija 12.13  Cena  10.48\n",
      "Predikcija 109.97  Cena  171.18\n",
      "Predikcija 5.83  Cena  4.62\n",
      "Predikcija 0.47  Cena  0.42\n",
      "Predikcija 7.08  Cena  8.82\n",
      "Predikcija 0.48  Cena  0.4\n",
      "Predikcija 132.02  Cena  132.82\n",
      "Predikcija 6.49  Cena  4.49\n",
      "Predikcija 1.04  Cena  0.9\n",
      "Predikcija 1.46  Cena  0.95\n",
      "Predikcija 17.76  Cena  23.98\n",
      "Predikcija 272.0  Cena  252.68\n",
      "Predikcija 23.11  Cena  18.86\n",
      "Predikcija 16.97  Cena  15.76\n",
      "Predikcija 10.74  Cena  9.47\n",
      "Predikcija 2.49  Cena  1.45\n",
      "Predikcija 113.5  Cena  117.49\n",
      "Predikcija 16.16  Cena  10.82\n",
      "MAE [6.75877]\n",
      "MAPE [0.307868]\n",
      "RMSE [14.885205]\n"
     ]
    }
   ],
   "source": [
    "mae = 0\n",
    "mape = 0\n",
    "rmse = 0\n",
    "c = 0\n",
    "for e,i in zip(np.exp(preds),y_test):\n",
    "  mae = mae + abs(e-i)\n",
    "  mape = mape + abs((e-i)/i)\n",
    "  rmse = rmse + np.power((i-e),2)\n",
    "  c = c +1 \n",
    "  print(\"Predikcija\",round(e[0],2),\" Cena \",round(i,2))\n",
    "print(\"MAE\",mae/c)\n",
    "print(\"MAPE\",mape/c)\n",
    "print(\"RMSE\",np.sqrt(rmse/c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xLIsf-ojP0Cl",
    "outputId": "7b915906-7c67-45c2-8131-9042a42688a2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.18 , 2.6\n",
      "41.08 , 38.24\n",
      "7.2 , 5.34\n",
      "11.6 , 9.56\n",
      "68.64 , 90.1\n",
      "19.8 , 11.34\n",
      "9.83 , 8.12\n",
      "2.08 , 1.99\n",
      "15.96 , 14.89\n",
      "13.4 , 8.58\n",
      "18.1 , 16.09\n",
      "43.98 , 36.27\n",
      "4.4 , 1.76\n",
      "14.43 , 6.81\n",
      "15.02 , 9.04\n",
      "11.17 , 10.26\n",
      "68.8 , 126.5\n",
      "73.0 , 66.36\n",
      "13.89 , 14.33\n",
      "46.43 , 38.22\n",
      "12.13 , 10.48\n",
      "109.97 , 171.18\n",
      "5.83 , 4.62\n",
      "0.47 , 0.42\n",
      "7.08 , 8.82\n",
      "0.48 , 0.4\n",
      "132.02 , 132.82\n",
      "6.49 , 4.49\n",
      "1.04 , 0.9\n",
      "1.46 , 0.95\n",
      "17.76 , 23.98\n",
      "272.0 , 252.68\n",
      "23.11 , 18.86\n",
      "16.97 , 15.76\n",
      "10.74 , 9.47\n",
      "2.49 , 1.45\n",
      "113.5 , 117.49\n",
      "16.16 , 10.82\n",
      "[6.75877]\n",
      "[0.307868]\n",
      "[14.885205]\n"
     ]
    }
   ],
   "source": [
    "for e,i in zip(np.exp(preds),y_test):\n",
    "  print(round(e[0],2),\",\",round(i,2))\n",
    "\n",
    "print(mae/c)\n",
    "print(mape/c)\n",
    "print(np.sqrt(rmse/c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NpPJ9gHDYs6A",
    "outputId": "b5b99a93-3d9e-4649-b6d9-d4f63781b93b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(model,\n",
    "    to_file=\"model.png\",\n",
    "    show_shapes=False,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    "    layer_range=None,\n",
    "    show_layer_activations=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________\n",
      "train (150, 100, 100, 100, 1) (150, 1) (150, 1)\n",
      "test (38, 100, 100, 100, 1) (38, 1) (38, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 16:39:59.847627: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-05 16:39:59.898192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 0 with properties: \n",
      "pciBusID: 0000:21:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-01-05 16:39:59.898234: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-05 16:39:59.913461: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcublas.so.11\n",
      "2022-01-05 16:39:59.913536: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-01-05 16:39:59.920204: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-05 16:39:59.922100: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-05 16:39:59.939065: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcutensor.so.1\n",
      "2022-01-05 16:39:59.941109: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-01-05 16:39:59.945781: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-01-05 16:39:59.946576: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-01-05 16:39:59.947283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1872] Adding visible gpu devices: 0\n",
      "2022-01-05 16:39:59.948680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 0 with properties: \n",
      "pciBusID: 0000:21:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-01-05 16:39:59.948969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1872] Adding visible gpu devices: 0\n",
      "2022-01-05 16:39:59.949226: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-05 16:40:00.744715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-01-05 16:40:00.744753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-01-05 16:40:00.744778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-01-05 16:40:00.745364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9649 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:21:00.0, compute capability: 7.5)\n",
      "2022-01-05 16:40:00.746626: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 20. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "starting round lr 0.0001  and seed 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 16:40:01.437732: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-01-05 16:40:01.456559: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3299990000 Hz\n",
      "2022-01-05 16:40:02.068819: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-01-05 16:40:02.781367: I tensorflow/stream_executor/cuda/cuda_dnn.cc:380] Loaded cuDNN version 8202\n",
      "2022-01-05 16:40:03.635594: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcublas.so.11\n",
      "2022-01-05 16:40:04.416894: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for round: 0.0001  seed 12\n",
      "57.01 , 35.47\n",
      "12.72 , 9.5\n",
      "75.63 , 51.93\n",
      "41.47 , 62.18\n",
      "82.85 , 69.82\n",
      "45.06 , 61.51\n",
      "8.88 , 5.75\n",
      "52.15 , 29.22\n",
      "8.63 , 5.79\n",
      "18.52 , 7.76\n",
      "13.86 , 13.95\n",
      "10.61 , 4.05\n",
      "32.64 , 57.87\n",
      "47.5 , 32.23\n",
      "1.33 , 0.9\n",
      "10.23 , 11.02\n",
      "1.05 , 0.63\n",
      "6.93 , 6.15\n",
      "1.09 , 0.56\n",
      "41.49 , 30.78\n",
      "4.46 , 5.15\n",
      "7.93 , 8.82\n",
      "18.9 , 26.78\n",
      "3.31 , 2.6\n",
      "7.23 , 6.58\n",
      "8.97 , 12.58\n",
      "2.45 , 1.39\n",
      "22.77 , 15.75\n",
      "14.22 , 10.48\n",
      "25.91 , 22.49\n",
      "40.09 , 90.1\n",
      "18.33 , 7.06\n",
      "117.4 , 117.49\n",
      "2.15 , 0.82\n",
      "49.6 , 38.24\n",
      "13.55 , 9.47\n",
      "28.07 , 33.02\n",
      "6.13 , 5.86\n",
      "[8.21389]\n",
      "[0.4778966]\n",
      "[13.125989]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 8e-05  and seed 12\n",
      "results for round: 8e-05  seed 12\n",
      "43.34 , 35.47\n",
      "10.76 , 9.5\n",
      "58.51 , 51.93\n",
      "28.89 , 62.18\n",
      "63.09 , 69.82\n",
      "31.62 , 61.51\n",
      "9.12 , 5.75\n",
      "35.58 , 29.22\n",
      "7.82 , 5.79\n",
      "14.27 , 7.76\n",
      "11.6 , 13.95\n",
      "8.33 , 4.05\n",
      "24.98 , 57.87\n",
      "37.45 , 32.23\n",
      "1.05 , 0.9\n",
      "8.97 , 11.02\n",
      "0.72 , 0.63\n",
      "5.93 , 6.15\n",
      "0.9 , 0.56\n",
      "33.66 , 30.78\n",
      "3.89 , 5.15\n",
      "6.73 , 8.82\n",
      "13.85 , 26.78\n",
      "2.94 , 2.6\n",
      "6.38 , 6.58\n",
      "8.25 , 12.58\n",
      "2.1 , 1.39\n",
      "19.18 , 15.75\n",
      "11.18 , 10.48\n",
      "20.28 , 22.49\n",
      "39.43 , 90.1\n",
      "13.88 , 7.06\n",
      "90.64 , 117.49\n",
      "1.71 , 0.82\n",
      "38.67 , 38.24\n",
      "10.92 , 9.47\n",
      "23.71 , 33.02\n",
      "5.08 , 5.86\n",
      "[7.36203]\n",
      "[0.33058205]\n",
      "[13.603928]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 4e-05  and seed 12\n",
      "results for round: 4e-05  seed 12\n",
      "48.08 , 35.47\n",
      "11.19 , 9.5\n",
      "62.55 , 51.93\n",
      "34.94 , 62.18\n",
      "63.36 , 69.82\n",
      "34.57 , 61.51\n",
      "9.23 , 5.75\n",
      "38.37 , 29.22\n",
      "7.86 , 5.79\n",
      "14.41 , 7.76\n",
      "12.14 , 13.95\n",
      "8.72 , 4.05\n",
      "26.24 , 57.87\n",
      "42.72 , 32.23\n",
      "1.03 , 0.9\n",
      "10.1 , 11.02\n",
      "0.72 , 0.63\n",
      "6.53 , 6.15\n",
      "0.87 , 0.56\n",
      "37.55 , 30.78\n",
      "4.11 , 5.15\n",
      "7.34 , 8.82\n",
      "14.0 , 26.78\n",
      "3.27 , 2.6\n",
      "7.64 , 6.58\n",
      "8.86 , 12.58\n",
      "2.34 , 1.39\n",
      "18.03 , 15.75\n",
      "10.46 , 10.48\n",
      "22.14 , 22.49\n",
      "47.34 , 90.1\n",
      "14.66 , 7.06\n",
      "109.71 , 117.49\n",
      "1.86 , 0.82\n",
      "38.18 , 38.24\n",
      "11.88 , 9.47\n",
      "26.84 , 33.02\n",
      "6.08 , 5.86\n",
      "[6.750831]\n",
      "[0.34154406]\n",
      "[11.800219]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 2e-05  and seed 12\n",
      "results for round: 2e-05  seed 12\n",
      "46.34 , 35.47\n",
      "11.32 , 9.5\n",
      "60.66 , 51.93\n",
      "34.31 , 62.18\n",
      "60.86 , 69.82\n",
      "34.62 , 61.51\n",
      "9.29 , 5.75\n",
      "36.89 , 29.22\n",
      "7.98 , 5.79\n",
      "13.4 , 7.76\n",
      "12.77 , 13.95\n",
      "7.66 , 4.05\n",
      "27.08 , 57.87\n",
      "41.84 , 32.23\n",
      "1.07 , 0.9\n",
      "10.32 , 11.02\n",
      "0.66 , 0.63\n",
      "6.49 , 6.15\n",
      "0.84 , 0.56\n",
      "36.94 , 30.78\n",
      "4.13 , 5.15\n",
      "7.14 , 8.82\n",
      "13.08 , 26.78\n",
      "3.05 , 2.6\n",
      "7.53 , 6.58\n",
      "9.29 , 12.58\n",
      "2.28 , 1.39\n",
      "18.13 , 15.75\n",
      "10.39 , 10.48\n",
      "21.36 , 22.49\n",
      "46.79 , 90.1\n",
      "13.48 , 7.06\n",
      "110.19 , 117.49\n",
      "1.82 , 0.82\n",
      "37.15 , 38.24\n",
      "11.61 , 9.47\n",
      "26.39 , 33.02\n",
      "5.66 , 5.86\n",
      "[6.597433]\n",
      "[0.31604743]\n",
      "[11.709888]\n",
      " \n",
      "next round!\n",
      "______________________________________________\n",
      "train (150, 100, 100, 100, 1) (150, 1) (150, 1)\n",
      "test (38, 100, 100, 100, 1) (38, 1) (38, 1)\n",
      " \n",
      "starting round lr 0.0001  and seed 36\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe8d4be5160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "results for round: 0.0001  seed 36\n",
      "3.6 , 2.6\n",
      "38.86 , 38.24\n",
      "7.91 , 5.34\n",
      "11.31 , 9.56\n",
      "48.6 , 90.1\n",
      "18.84 , 11.34\n",
      "8.32 , 8.12\n",
      "2.42 , 1.99\n",
      "14.29 , 14.89\n",
      "10.25 , 8.58\n",
      "17.15 , 16.09\n",
      "35.44 , 36.27\n",
      "4.31 , 1.76\n",
      "15.64 , 6.81\n",
      "12.2 , 9.04\n",
      "7.09 , 10.26\n",
      "75.91 , 126.5\n",
      "92.89 , 66.36\n",
      "13.44 , 14.33\n",
      "29.74 , 38.22\n",
      "12.76 , 10.48\n",
      "105.12 , 171.18\n",
      "5.71 , 4.62\n",
      "0.51 , 0.42\n",
      "8.35 , 8.82\n",
      "0.86 , 0.4\n",
      "123.53 , 132.82\n",
      "6.5 , 4.49\n",
      "1.29 , 0.9\n",
      "2.83 , 0.95\n",
      "11.53 , 23.98\n",
      "272.07 , 252.68\n",
      "22.54 , 18.86\n",
      "16.54 , 15.76\n",
      "9.75 , 9.47\n",
      "2.72 , 1.45\n",
      "91.37 , 117.49\n",
      "15.24 , 10.82\n",
      "[8.325157]\n",
      "[0.38994983]\n",
      "[16.975134]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 8e-05  and seed 36\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe8f76e63a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "results for round: 8e-05  seed 36\n",
      "2.83 , 2.6\n",
      "45.67 , 38.24\n",
      "5.79 , 5.34\n",
      "11.69 , 9.56\n",
      "47.81 , 90.1\n",
      "16.34 , 11.34\n",
      "9.3 , 8.12\n",
      "1.76 , 1.99\n",
      "14.78 , 14.89\n",
      "12.47 , 8.58\n",
      "19.28 , 16.09\n",
      "41.32 , 36.27\n",
      "4.17 , 1.76\n",
      "15.13 , 6.81\n",
      "14.94 , 9.04\n",
      "7.61 , 10.26\n",
      "61.79 , 126.5\n",
      "100.01 , 66.36\n",
      "11.43 , 14.33\n",
      "32.01 , 38.22\n",
      "14.0 , 10.48\n",
      "117.48 , 171.18\n",
      "5.06 , 4.62\n",
      "0.44 , 0.42\n",
      "8.38 , 8.82\n",
      "0.63 , 0.4\n",
      "131.24 , 132.82\n",
      "6.73 , 4.49\n",
      "0.99 , 0.9\n",
      "2.12 , 0.95\n",
      "14.93 , 23.98\n",
      "320.15 , 252.68\n",
      "24.15 , 18.86\n",
      "15.49 , 15.76\n",
      "10.54 , 9.47\n",
      "2.46 , 1.45\n",
      "115.21 , 117.49\n",
      "17.78 , 10.82\n",
      "[9.336262]\n",
      "[0.34544134]\n",
      "[19.890581]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 4e-05  and seed 36\n",
      "results for round: 4e-05  seed 36\n",
      "3.38 , 2.6\n",
      "42.87 , 38.24\n",
      "5.99 , 5.34\n",
      "11.26 , 9.56\n",
      "53.77 , 90.1\n",
      "19.36 , 11.34\n",
      "8.68 , 8.12\n",
      "2.14 , 1.99\n",
      "16.57 , 14.89\n",
      "11.95 , 8.58\n",
      "17.74 , 16.09\n",
      "40.15 , 36.27\n",
      "4.17 , 1.76\n",
      "13.6 , 6.81\n",
      "13.75 , 9.04\n",
      "7.61 , 10.26\n",
      "66.13 , 126.5\n",
      "86.32 , 66.36\n",
      "12.23 , 14.33\n",
      "30.51 , 38.22\n",
      "12.13 , 10.48\n",
      "112.12 , 171.18\n",
      "6.31 , 4.62\n",
      "0.46 , 0.42\n",
      "8.01 , 8.82\n",
      "0.65 , 0.4\n",
      "116.91 , 132.82\n",
      "7.53 , 4.49\n",
      "1.12 , 0.9\n",
      "1.91 , 0.95\n",
      "14.5 , 23.98\n",
      "281.57 , 252.68\n",
      "22.2 , 18.86\n",
      "17.9 , 15.76\n",
      "10.21 , 9.47\n",
      "2.74 , 1.45\n",
      "104.84 , 117.49\n",
      "16.28 , 10.82\n",
      "[8.362454]\n",
      "[0.3454263]\n",
      "[16.639273]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 2e-05  and seed 36\n",
      "results for round: 2e-05  seed 36\n",
      "3.11 , 2.6\n",
      "42.68 , 38.24\n",
      "5.98 , 5.34\n",
      "11.27 , 9.56\n",
      "53.68 , 90.1\n",
      "18.09 , 11.34\n",
      "9.05 , 8.12\n",
      "1.87 , 1.99\n",
      "16.94 , 14.89\n",
      "11.94 , 8.58\n",
      "17.69 , 16.09\n",
      "40.44 , 36.27\n",
      "4.22 , 1.76\n",
      "12.92 , 6.81\n",
      "13.67 , 9.04\n",
      "7.83 , 10.26\n",
      "67.37 , 126.5\n",
      "89.9 , 66.36\n",
      "11.93 , 14.33\n",
      "30.47 , 38.22\n",
      "13.13 , 10.48\n",
      "117.69 , 171.18\n",
      "5.71 , 4.62\n",
      "0.44 , 0.42\n",
      "8.04 , 8.82\n",
      "0.6 , 0.4\n",
      "119.08 , 132.82\n",
      "7.77 , 4.49\n",
      "1.03 , 0.9\n",
      "1.78 , 0.95\n",
      "16.22 , 23.98\n",
      "288.22 , 252.68\n",
      "21.68 , 18.86\n",
      "17.54 , 15.76\n",
      "10.2 , 9.47\n",
      "2.52 , 1.45\n",
      "115.72 , 117.49\n",
      "17.44 , 10.82\n",
      "[8.039797]\n",
      "[0.32262817]\n",
      "[16.281374]\n",
      " \n",
      "next round!\n",
      "______________________________________________\n",
      "train (150, 100, 100, 100, 1) (150, 1) (150, 1)\n",
      "test (38, 100, 100, 100, 1) (38, 1) (38, 1)\n",
      " \n",
      "starting round lr 0.0001  and seed 42\n",
      "results for round: 0.0001  seed 42\n",
      "25.68 , 18.86\n",
      "4.0 , 1.64\n",
      "9.48 , 7.42\n",
      "7.32 , 3.91\n",
      "76.51 , 30.84\n",
      "115.01 , 90.17\n",
      "28.91 , 9.5\n",
      "19.85 , 32.13\n",
      "9.56 , 14.33\n",
      "31.87 , 36.27\n",
      "54.82 , 38.4\n",
      "10.2 , 4.49\n",
      "0.38 , 0.17\n",
      "24.58 , 17.66\n",
      "40.44 , 61.51\n",
      "22.38 , 13.95\n",
      "11.37 , 5.66\n",
      "19.73 , 14.49\n",
      "8.99 , 7.43\n",
      "0.9 , 0.4\n",
      "9.72 , 3.42\n",
      "333.92 , 252.68\n",
      "10.42 , 7.06\n",
      "86.39 , 308.13\n",
      "5.62 , 5.34\n",
      "8.86 , 11.02\n",
      "2.63 , 1.39\n",
      "9.56 , 3.12\n",
      "33.5 , 33.02\n",
      "17.61 , 12.16\n",
      "17.78 , 5.41\n",
      "2.48 , 2.72\n",
      "21.59 , 63.85\n",
      "24.45 , 10.29\n",
      "2.45 , 0.85\n",
      "16.64 , 10.48\n",
      "20.87 , 15.76\n",
      "26.07 , 17.72\n",
      "[16.229422]\n",
      "[0.7740868]\n",
      "[40.53563]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 8e-05  and seed 42\n",
      "results for round: 8e-05  seed 42\n",
      "22.76 , 18.86\n",
      "3.31 , 1.64\n",
      "8.27 , 7.42\n",
      "6.15 , 3.91\n",
      "74.81 , 30.84\n",
      "84.06 , 90.17\n",
      "24.73 , 9.5\n",
      "15.6 , 32.13\n",
      "8.53 , 14.33\n",
      "29.65 , 36.27\n",
      "55.59 , 38.4\n",
      "9.31 , 4.49\n",
      "0.32 , 0.17\n",
      "20.81 , 17.66\n",
      "27.8 , 61.51\n",
      "16.31 , 13.95\n",
      "9.78 , 5.66\n",
      "17.38 , 14.49\n",
      "7.75 , 7.43\n",
      "0.81 , 0.4\n",
      "8.56 , 3.42\n",
      "313.69 , 252.68\n",
      "8.91 , 7.06\n",
      "70.21 , 308.13\n",
      "4.59 , 5.34\n",
      "8.62 , 11.02\n",
      "2.24 , 1.39\n",
      "6.82 , 3.12\n",
      "32.2 , 33.02\n",
      "14.71 , 12.16\n",
      "12.84 , 5.41\n",
      "2.2 , 2.72\n",
      "14.07 , 63.85\n",
      "18.41 , 10.29\n",
      "1.95 , 0.85\n",
      "14.75 , 10.48\n",
      "17.58 , 15.76\n",
      "24.19 , 17.72\n",
      "[14.962041]\n",
      "[0.57679063]\n",
      "[42.02773]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 4e-05  and seed 42\n",
      "results for round: 4e-05  seed 42\n",
      "20.81 , 18.86\n",
      "2.86 , 1.64\n",
      "7.77 , 7.42\n",
      "5.96 , 3.91\n",
      "66.97 , 30.84\n",
      "76.41 , 90.17\n",
      "21.82 , 9.5\n",
      "14.77 , 32.13\n",
      "7.94 , 14.33\n",
      "28.09 , 36.27\n",
      "51.8 , 38.4\n",
      "9.52 , 4.49\n",
      "0.29 , 0.17\n",
      "20.07 , 17.66\n",
      "26.97 , 61.51\n",
      "15.33 , 13.95\n",
      "9.01 , 5.66\n",
      "16.16 , 14.49\n",
      "7.44 , 7.43\n",
      "0.78 , 0.4\n",
      "7.79 , 3.42\n",
      "278.82 , 252.68\n",
      "8.48 , 7.06\n",
      "66.51 , 308.13\n",
      "4.11 , 5.34\n",
      "8.28 , 11.02\n",
      "2.17 , 1.39\n",
      "5.85 , 3.12\n",
      "33.84 , 33.02\n",
      "13.91 , 12.16\n",
      "10.73 , 5.41\n",
      "2.14 , 2.72\n",
      "12.71 , 63.85\n",
      "17.15 , 10.29\n",
      "1.83 , 0.85\n",
      "15.8 , 10.48\n",
      "17.85 , 15.76\n",
      "24.84 , 17.72\n",
      "[13.815876]\n",
      "[0.5062086]\n",
      "[41.473694]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 2e-05  and seed 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for round: 2e-05  seed 42\n",
      "21.64 , 18.86\n",
      "2.86 , 1.64\n",
      "8.03 , 7.42\n",
      "6.34 , 3.91\n",
      "66.23 , 30.84\n",
      "75.62 , 90.17\n",
      "21.46 , 9.5\n",
      "16.48 , 32.13\n",
      "8.5 , 14.33\n",
      "31.44 , 36.27\n",
      "53.89 , 38.4\n",
      "9.77 , 4.49\n",
      "0.28 , 0.17\n",
      "20.9 , 17.66\n",
      "28.42 , 61.51\n",
      "16.01 , 13.95\n",
      "9.3 , 5.66\n",
      "16.41 , 14.49\n",
      "7.75 , 7.43\n",
      "0.86 , 0.4\n",
      "7.85 , 3.42\n",
      "291.63 , 252.68\n",
      "9.33 , 7.06\n",
      "73.52 , 308.13\n",
      "4.8 , 5.34\n",
      "8.89 , 11.02\n",
      "2.42 , 1.39\n",
      "5.61 , 3.12\n",
      "35.21 , 33.02\n",
      "14.33 , 12.16\n",
      "10.78 , 5.41\n",
      "2.56 , 2.72\n",
      "14.17 , 63.85\n",
      "17.88 , 10.29\n",
      "1.91 , 0.85\n",
      "16.55 , 10.48\n",
      "17.48 , 15.76\n",
      "25.45 , 17.72\n",
      "[13.974894]\n",
      "[0.5226754]\n",
      "[40.58042]\n",
      " \n",
      "next round!\n"
     ]
    }
   ],
   "source": [
    "#vox \n",
    "epochs_per_round = 150\n",
    "seeds = [12,36,42]\n",
    "#seeds = [42]\n",
    "rounds_lr = [0.0001,0.00008,0.00004,0.00002]\n",
    "\n",
    "for seed in seeds:\n",
    "\n",
    "    print(\"______________________________________________\")\n",
    "\n",
    "\n",
    "    n_samples = X.shape[0]\n",
    "    train_ind, test_ind  = train_test_split(range(n_samples), test_size=0.2, random_state=seed)\n",
    "\n",
    "    X_train = X[train_ind]\n",
    "    X_train_volume = X_volume[train_ind]\n",
    "    X_train_area = X_area[train_ind]\n",
    "    y_train = y[train_ind]\n",
    "\n",
    "    X_test = X[test_ind]\n",
    "    X_test_volume = X_volume[test_ind]\n",
    "    X_test_area = X_area[test_ind]\n",
    "    y_test = y[test_ind]\n",
    "\n",
    "    print(\"train\",X_train.shape,X_train_volume.shape,X_train_area.shape)\n",
    "    print(\"test\",X_test.shape,X_test_volume.shape,X_test_area.shape)\n",
    "\n",
    "    #my net\n",
    "    input1 = keras.Input(shape=(X_train.shape[1:]))\n",
    "    input2 = keras.Input(shape=(X_train_volume.shape[1:]))\n",
    "    input3 = keras.Input(shape=(X_train_area.shape[1:]))\n",
    "\n",
    "    #y = Dense(1)(input2)\n",
    "    activ = \"LeakyReLU\"\n",
    "    # x = Conv3D(64,(7,7,7),strides = (2,2,2), activation=activ, padding = 'same')(input1)\n",
    "    # x = Conv3D(64,(7,7,7),strides = (2,2,2), activation=activ, padding = 'same')(x)\n",
    "    # x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "    # x = layers.Dropout(0.3)(x)\n",
    "    n=3\n",
    "    x = Conv3D(32,(n,n,n),strides = (2,2,2), activation=activ, padding = 'same')(input1)\n",
    "    x = Conv3D(32,(n,n,n),strides = (2,2,2), activation=activ, padding = 'same')(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv3D(16,(n,n,n), activation=activ, padding = 'same')(x)\n",
    "    x = Conv3D(16,(n,n,n),strides = (2,2,2), activation=activ, padding = 'same')(x)\n",
    "    x = MaxPooling3D(pool_size=(1, 1, 1))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv3D(8,(n,n,n),strides = (2,2,2), activation=activ, padding = 'same')(x)\n",
    "    x = Conv3D(8,(n,n,n),strides = (2,2,2), activation=activ, padding = 'same')(x)\n",
    "    x = MaxPooling3D(pool_size=(1, 1, 1))(x)\n",
    "\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = layers.Concatenate(axis=1)([x,input2])\n",
    "    #x = Dense(4, activation = 'relu')(x)\n",
    "    x = layers.Concatenate(axis=1)([x,input3])\n",
    "\n",
    "    dense = Dense(2000, activation = activ)(x)\n",
    "    dense = Dense(300, activation = activ)(dense)\n",
    "    dense = Dense(150, activation = activ)(dense)\n",
    "    dense = Dense(20, activation = activ)(dense)\n",
    "    dense = Dense(16, activation = activ)(dense)\n",
    "        # final layer with 10 neurons to classify the instances\n",
    "    output = Dense(1, activation = 'linear')(dense)\n",
    "\n",
    "    #outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input1,input2,input3], outputs=output, name=\"jjnet\")\n",
    "\n",
    "    for round_lr in rounds_lr:\n",
    "        \n",
    "        print(\" \")\n",
    "        print(\"starting round lr\",round_lr,\" and seed\",seed)\n",
    "\n",
    "        model.compile(\n",
    "            loss=\"MAE\",\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=round_lr),\n",
    "            metrics=[\"MAPE\"],\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        model.fit([X_train,np.log(X_train_volume), np.log(X_train_area)], np.log(y_train), batch_size = 8, epochs = epochs_per_round, verbose = 0)\n",
    "        #model.fit([X_train,X_train_volume, X_train_area], np.log(y_train),validation_split = 0.2, batch_size = 8, epochs = 100, verbose = 1)\n",
    "        #model.evaluate([X_test, np.log(X_test_volume),np.log(X_test_area)],y_test)\n",
    "\n",
    "        preds = model.predict([X_test, np.log(X_test_volume),np.log(X_test_area)])#*y_train_max\n",
    "        #preds = model.predict([X_test,X_test_volume,X_test_area])#*y_train_max\n",
    "\n",
    "        mae = 0\n",
    "        mape = 0\n",
    "        rmse = 0\n",
    "        c = 0\n",
    "        for e,i in zip(np.exp(preds),y_test):\n",
    "          mae = mae + abs(e-i)\n",
    "          mape = mape + abs((e-i)/i)\n",
    "          rmse = rmse + np.power((i-e),2)\n",
    "          c = c +1 \n",
    "\n",
    "        print(\"results for round:\",round_lr,\" seed\",seed)\n",
    "        for e,i in zip(np.exp(preds),y_test):\n",
    "          print(round(e[0],2),\",\",round(i,2))\n",
    "\n",
    "        print(mae/c)\n",
    "        print(mape/c)\n",
    "        print(np.sqrt(rmse/c))\n",
    "        print(\" \")\n",
    "        print(\"next round!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________\n",
      "train (150, 100, 100, 100, 1) (150, 1) (150, 1)\n",
      "test (38, 100, 100, 100, 1) (38, 1) (38, 1)\n",
      " \n",
      "starting round lr 0.001  and seed 12\n",
      "results for round: 0.001  seed 12\n",
      "34.3 , 35.47\n",
      "6.65 , 9.5\n",
      "43.27 , 51.93\n",
      "22.81 , 62.18\n",
      "44.58 , 69.82\n",
      "26.86 , 61.51\n",
      "4.33 , 5.75\n",
      "17.37 , 29.22\n",
      "4.09 , 5.79\n",
      "5.96 , 7.76\n",
      "11.35 , 13.95\n",
      "4.8 , 4.05\n",
      "38.58 , 57.87\n",
      "21.37 , 32.23\n",
      "0.75 , 0.9\n",
      "12.43 , 11.02\n",
      "0.51 , 0.63\n",
      "5.02 , 6.15\n",
      "0.43 , 0.56\n",
      "30.48 , 30.78\n",
      "3.03 , 5.15\n",
      "5.35 , 8.82\n",
      "8.16 , 26.78\n",
      "2.1 , 2.6\n",
      "6.19 , 6.58\n",
      "15.23 , 12.58\n",
      "1.69 , 1.39\n",
      "10.29 , 15.75\n",
      "14.69 , 10.48\n",
      "18.01 , 22.49\n",
      "61.85 , 90.1\n",
      "5.76 , 7.06\n",
      "134.23 , 117.49\n",
      "0.39 , 0.82\n",
      "30.28 , 38.24\n",
      "8.41 , 9.47\n",
      "19.85 , 33.02\n",
      "5.91 , 5.86\n",
      "[7.279944]\n",
      "[0.26857635]\n",
      "[12.437867]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 0.0008  and seed 12\n",
      "results for round: 0.0008  seed 12\n",
      "48.23 , 35.47\n",
      "9.88 , 9.5\n",
      "63.42 , 51.93\n",
      "29.31 , 62.18\n",
      "63.89 , 69.82\n",
      "38.41 , 61.51\n",
      "5.6 , 5.75\n",
      "21.71 , 29.22\n",
      "4.84 , 5.79\n",
      "7.27 , 7.76\n",
      "14.6 , 13.95\n",
      "5.68 , 4.05\n",
      "51.86 , 57.87\n",
      "28.7 , 32.23\n",
      "0.85 , 0.9\n",
      "17.85 , 11.02\n",
      "0.57 , 0.63\n",
      "6.39 , 6.15\n",
      "0.52 , 0.56\n",
      "38.79 , 30.78\n",
      "3.79 , 5.15\n",
      "6.79 , 8.82\n",
      "9.22 , 26.78\n",
      "2.07 , 2.6\n",
      "7.25 , 6.58\n",
      "19.61 , 12.58\n",
      "1.58 , 1.39\n",
      "15.97 , 15.75\n",
      "12.89 , 10.48\n",
      "24.13 , 22.49\n",
      "85.28 , 90.1\n",
      "6.7 , 7.06\n",
      "191.58 , 117.49\n",
      "0.53 , 0.82\n",
      "40.58 , 38.24\n",
      "11.44 , 9.47\n",
      "26.4 , 33.02\n",
      "7.2 , 5.86\n",
      "[6.529779]\n",
      "[0.21510997]\n",
      "[14.604125]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 0.0004  and seed 12\n",
      "results for round: 0.0004  seed 12\n",
      "38.52 , 35.47\n",
      "8.25 , 9.5\n",
      "51.75 , 51.93\n",
      "24.08 , 62.18\n",
      "52.05 , 69.82\n",
      "31.35 , 61.51\n",
      "4.75 , 5.75\n",
      "17.99 , 29.22\n",
      "4.19 , 5.79\n",
      "6.44 , 7.76\n",
      "11.74 , 13.95\n",
      "4.92 , 4.05\n",
      "47.21 , 57.87\n",
      "24.59 , 32.23\n",
      "0.62 , 0.9\n",
      "14.99 , 11.02\n",
      "0.48 , 0.63\n",
      "5.38 , 6.15\n",
      "0.44 , 0.56\n",
      "29.9 , 30.78\n",
      "3.28 , 5.15\n",
      "5.7 , 8.82\n",
      "7.08 , 26.78\n",
      "1.84 , 2.6\n",
      "6.23 , 6.58\n",
      "16.54 , 12.58\n",
      "1.29 , 1.39\n",
      "15.9 , 15.75\n",
      "9.54 , 10.48\n",
      "19.94 , 22.49\n",
      "70.34 , 90.1\n",
      "6.29 , 7.06\n",
      "183.09 , 117.49\n",
      "0.43 , 0.82\n",
      "36.64 , 38.24\n",
      "9.3 , 9.47\n",
      "22.43 , 33.02\n",
      "6.16 , 5.86\n",
      "[6.998005]\n",
      "[0.23322387]\n",
      "[14.733115]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 0.0002  and seed 12\n",
      "results for round: 0.0002  seed 12\n",
      "42.93 , 35.47\n",
      "9.16 , 9.5\n",
      "57.4 , 51.93\n",
      "26.34 , 62.18\n",
      "56.92 , 69.82\n",
      "35.76 , 61.51\n",
      "5.22 , 5.75\n",
      "19.68 , 29.22\n",
      "4.91 , 5.79\n",
      "7.12 , 7.76\n",
      "13.31 , 13.95\n",
      "5.31 , 4.05\n",
      "52.39 , 57.87\n",
      "27.21 , 32.23\n",
      "0.87 , 0.9\n",
      "16.87 , 11.02\n",
      "0.5 , 0.63\n",
      "6.11 , 6.15\n",
      "0.46 , 0.56\n",
      "34.05 , 30.78\n",
      "3.62 , 5.15\n",
      "6.48 , 8.82\n",
      "8.42 , 26.78\n",
      "2.15 , 2.6\n",
      "6.82 , 6.58\n",
      "18.13 , 12.58\n",
      "1.6 , 1.39\n",
      "16.79 , 15.75\n",
      "10.82 , 10.48\n",
      "22.28 , 22.49\n",
      "76.56 , 90.1\n",
      "7.01 , 7.06\n",
      "193.33 , 117.49\n",
      "0.45 , 0.82\n",
      "39.31 , 38.24\n",
      "10.41 , 9.47\n",
      "25.17 , 33.02\n",
      "6.64 , 5.86\n",
      "[6.6290956]\n",
      "[0.20431753]\n",
      "[15.19335]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 0.0001  and seed 12\n",
      "results for round: 0.0001  seed 12\n",
      "39.2 , 35.47\n",
      "8.62 , 9.5\n",
      "53.34 , 51.93\n",
      "25.33 , 62.18\n",
      "51.39 , 69.82\n",
      "33.22 , 61.51\n",
      "4.89 , 5.75\n",
      "18.72 , 29.22\n",
      "4.6 , 5.79\n",
      "6.7 , 7.76\n",
      "12.91 , 13.95\n",
      "5.14 , 4.05\n",
      "49.37 , 57.87\n",
      "26.03 , 32.23\n",
      "0.84 , 0.9\n",
      "16.65 , 11.02\n",
      "0.46 , 0.63\n",
      "5.73 , 6.15\n",
      "0.43 , 0.56\n",
      "30.59 , 30.78\n",
      "3.46 , 5.15\n",
      "6.09 , 8.82\n",
      "7.99 , 26.78\n",
      "2.11 , 2.6\n",
      "6.52 , 6.58\n",
      "16.84 , 12.58\n",
      "1.48 , 1.39\n",
      "17.04 , 15.75\n",
      "10.11 , 10.48\n",
      "20.64 , 22.49\n",
      "70.13 , 90.1\n",
      "6.6 , 7.06\n",
      "178.96 , 117.49\n",
      "0.42 , 0.82\n",
      "37.41 , 38.24\n",
      "9.6 , 9.47\n",
      "23.47 , 33.02\n",
      "6.38 , 5.86\n",
      "[6.621089]\n",
      "[0.21245046]\n",
      "[13.983133]\n",
      " \n",
      "next round!\n",
      "______________________________________________\n",
      "train (150, 100, 100, 100, 1) (150, 1) (150, 1)\n",
      "test (38, 100, 100, 100, 1) (38, 1) (38, 1)\n",
      " \n",
      "starting round lr 0.001  and seed 36\n",
      "results for round: 0.001  seed 36\n",
      "2.59 , 2.6\n",
      "53.27 , 38.24\n",
      "6.29 , 5.34\n",
      "10.86 , 9.56\n",
      "59.95 , 90.1\n",
      "7.44 , 11.34\n",
      "18.99 , 8.12\n",
      "2.31 , 1.99\n",
      "20.88 , 14.89\n",
      "33.8 , 8.58\n",
      "15.87 , 16.09\n",
      "41.41 , 36.27\n",
      "1.19 , 1.76\n",
      "10.77 , 6.81\n",
      "28.66 , 9.04\n",
      "9.76 , 10.26\n",
      "83.57 , 126.5\n",
      "69.01 , 66.36\n",
      "12.7 , 14.33\n",
      "41.69 , 38.22\n",
      "22.16 , 10.48\n",
      "188.94 , 171.18\n",
      "4.11 , 4.62\n",
      "0.65 , 0.42\n",
      "6.96 , 8.82\n",
      "0.46 , 0.4\n",
      "160.96 , 132.82\n",
      "5.4 , 4.49\n",
      "0.71 , 0.9\n",
      "2.32 , 0.95\n",
      "31.85 , 23.98\n",
      "243.43 , 252.68\n",
      "24.97 , 18.86\n",
      "11.35 , 15.76\n",
      "12.04 , 9.47\n",
      "1.25 , 1.45\n",
      "127.31 , 117.49\n",
      "13.35 , 10.82\n",
      "[7.365321]\n",
      "[0.42369953]\n",
      "[12.353135]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 0.0008  and seed 36\n",
      "results for round: 0.0008  seed 36\n",
      "2.98 , 2.6\n",
      "42.59 , 38.24\n",
      "5.83 , 5.34\n",
      "9.36 , 9.56\n",
      "62.02 , 90.1\n",
      "7.77 , 11.34\n",
      "15.08 , 8.12\n",
      "2.58 , 1.99\n",
      "24.14 , 14.89\n",
      "31.76 , 8.58\n",
      "14.15 , 16.09\n",
      "38.03 , 36.27\n",
      "1.29 , 1.76\n",
      "8.05 , 6.81\n",
      "23.69 , 9.04\n",
      "8.49 , 10.26\n",
      "87.07 , 126.5\n",
      "61.46 , 66.36\n",
      "11.12 , 14.33\n",
      "34.12 , 38.22\n",
      "18.05 , 10.48\n",
      "183.53 , 171.18\n",
      "4.48 , 4.62\n",
      "0.71 , 0.42\n",
      "6.12 , 8.82\n",
      "0.49 , 0.4\n",
      "123.24 , 132.82\n",
      "5.33 , 4.49\n",
      "0.74 , 0.9\n",
      "2.13 , 0.95\n",
      "30.08 , 23.98\n",
      "194.8 , 252.68\n",
      "17.75 , 18.86\n",
      "15.84 , 15.76\n",
      "10.05 , 9.47\n",
      "1.84 , 1.45\n",
      "101.35 , 117.49\n",
      "15.3 , 10.82\n",
      "[7.162709]\n",
      "[0.36212978]\n",
      "[13.865062]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 0.0004  and seed 36\n",
      "results for round: 0.0004  seed 36\n",
      "3.37 , 2.6\n",
      "48.38 , 38.24\n",
      "6.72 , 5.34\n",
      "10.98 , 9.56\n",
      "73.07 , 90.1\n",
      "8.51 , 11.34\n",
      "17.47 , 8.12\n",
      "2.48 , 1.99\n",
      "21.46 , 14.89\n",
      "35.25 , 8.58\n",
      "16.62 , 16.09\n",
      "46.31 , 36.27\n",
      "1.33 , 1.76\n",
      "9.52 , 6.81\n",
      "27.46 , 9.04\n",
      "9.51 , 10.26\n",
      "102.58 , 126.5\n",
      "68.98 , 66.36\n",
      "13.28 , 14.33\n",
      "40.66 , 38.22\n",
      "20.87 , 10.48\n",
      "193.75 , 171.18\n",
      "4.74 , 4.62\n",
      "0.92 , 0.42\n",
      "6.97 , 8.82\n",
      "0.52 , 0.4\n",
      "149.13 , 132.82\n",
      "5.88 , 4.49\n",
      "0.93 , 0.9\n",
      "2.14 , 0.95\n",
      "34.07 , 23.98\n",
      "249.36 , 252.68\n",
      "20.0 , 18.86\n",
      "15.96 , 15.76\n",
      "11.68 , 9.47\n",
      "1.68 , 1.45\n",
      "123.43 , 117.49\n",
      "16.91 , 10.82\n",
      "[5.875983]\n",
      "[0.41800287]\n",
      "[9.408123]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 0.0002  and seed 36\n",
      "results for round: 0.0002  seed 36\n",
      "3.23 , 2.6\n",
      "41.8 , 38.24\n",
      "6.01 , 5.34\n",
      "9.66 , 9.56\n",
      "66.61 , 90.1\n",
      "7.48 , 11.34\n",
      "14.76 , 8.12\n",
      "2.4 , 1.99\n",
      "18.22 , 14.89\n",
      "32.32 , 8.58\n",
      "14.26 , 16.09\n",
      "39.77 , 36.27\n",
      "1.17 , 1.76\n",
      "8.87 , 6.81\n",
      "24.61 , 9.04\n",
      "8.47 , 10.26\n",
      "91.51 , 126.5\n",
      "62.33 , 66.36\n",
      "11.71 , 14.33\n",
      "35.57 , 38.22\n",
      "17.65 , 10.48\n",
      "172.34 , 171.18\n",
      "4.44 , 4.62\n",
      "0.87 , 0.42\n",
      "6.18 , 8.82\n",
      "0.45 , 0.4\n",
      "122.57 , 132.82\n",
      "5.27 , 4.49\n",
      "0.87 , 0.9\n",
      "1.79 , 0.95\n",
      "30.63 , 23.98\n",
      "212.05 , 252.68\n",
      "18.56 , 18.86\n",
      "14.38 , 15.76\n",
      "10.23 , 9.47\n",
      "1.53 , 1.45\n",
      "104.17 , 117.49\n",
      "15.27 , 10.82\n",
      "[5.977808]\n",
      "[0.34220597]\n",
      "[11.216667]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 0.0001  and seed 36\n",
      "results for round: 0.0001  seed 36\n",
      "2.69 , 2.6\n",
      "38.51 , 38.24\n",
      "5.93 , 5.34\n",
      "9.36 , 9.56\n",
      "66.86 , 90.1\n",
      "7.3 , 11.34\n",
      "13.95 , 8.12\n",
      "1.95 , 1.99\n",
      "18.02 , 14.89\n",
      "30.23 , 8.58\n",
      "13.75 , 16.09\n",
      "36.86 , 36.27\n",
      "1.14 , 1.76\n",
      "8.3 , 6.81\n",
      "23.26 , 9.04\n",
      "8.3 , 10.26\n",
      "91.26 , 126.5\n",
      "56.85 , 66.36\n",
      "10.61 , 14.33\n",
      "33.34 , 38.22\n",
      "16.7 , 10.48\n",
      "162.6 , 171.18\n",
      "4.38 , 4.62\n",
      "0.85 , 0.42\n",
      "6.04 , 8.82\n",
      "0.47 , 0.4\n",
      "115.24 , 132.82\n",
      "5.22 , 4.49\n",
      "0.85 , 0.9\n",
      "1.56 , 0.95\n",
      "30.47 , 23.98\n",
      "196.54 , 252.68\n",
      "17.5 , 18.86\n",
      "14.82 , 15.76\n",
      "9.81 , 9.47\n",
      "1.58 , 1.45\n",
      "99.1 , 117.49\n",
      "15.84 , 10.82\n",
      "[6.83582]\n",
      "[0.31934443]\n",
      "[13.223083]\n",
      " \n",
      "next round!\n",
      "______________________________________________\n",
      "train (150, 100, 100, 100, 1) (150, 1) (150, 1)\n",
      "test (38, 100, 100, 100, 1) (38, 1) (38, 1)\n",
      " \n",
      "starting round lr 0.001  and seed 42\n",
      "results for round: 0.001  seed 42\n",
      "17.02 , 18.86\n",
      "1.88 , 1.64\n",
      "6.66 , 7.42\n",
      "3.54 , 3.91\n",
      "31.65 , 30.84\n",
      "69.42 , 90.17\n",
      "7.09 , 9.5\n",
      "49.79 , 32.13\n",
      "9.99 , 14.33\n",
      "31.54 , 36.27\n",
      "43.85 , 38.4\n",
      "5.25 , 4.49\n",
      "0.44 , 0.17\n",
      "18.36 , 17.66\n",
      "29.4 , 61.51\n",
      "11.65 , 13.95\n",
      "4.3 , 5.66\n",
      "11.78 , 14.49\n",
      "6.68 , 7.43\n",
      "0.47 , 0.4\n",
      "3.69 , 3.42\n",
      "169.79 , 252.68\n",
      "5.75 , 7.06\n",
      "177.48 , 308.13\n",
      "5.56 , 5.34\n",
      "12.4 , 11.02\n",
      "1.48 , 1.39\n",
      "2.88 , 3.12\n",
      "18.96 , 33.02\n",
      "11.53 , 12.16\n",
      "3.85 , 5.41\n",
      "1.75 , 2.72\n",
      "65.01 , 63.85\n",
      "5.8 , 10.29\n",
      "0.72 , 0.85\n",
      "15.1 , 10.48\n",
      "9.49 , 15.76\n",
      "14.38 , 17.72\n",
      "[9.333153]\n",
      "[0.24712422]\n",
      "[26.212782]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 0.0008  and seed 42\n",
      "results for round: 0.0008  seed 42\n",
      "20.03 , 18.86\n",
      "3.01 , 1.64\n",
      "8.01 , 7.42\n",
      "4.13 , 3.91\n",
      "40.73 , 30.84\n",
      "86.75 , 90.17\n",
      "11.06 , 9.5\n",
      "62.16 , 32.13\n",
      "11.62 , 14.33\n",
      "42.08 , 36.27\n",
      "68.0 , 38.4\n",
      "6.36 , 4.49\n",
      "0.2 , 0.17\n",
      "21.55 , 17.66\n",
      "46.41 , 61.51\n",
      "14.29 , 13.95\n",
      "4.57 , 5.66\n",
      "13.82 , 14.49\n",
      "7.74 , 7.43\n",
      "0.49 , 0.4\n",
      "4.09 , 3.42\n",
      "248.94 , 252.68\n",
      "7.37 , 7.06\n",
      "239.99 , 308.13\n",
      "6.48 , 5.34\n",
      "16.8 , 11.02\n",
      "2.06 , 1.39\n",
      "3.86 , 3.12\n",
      "25.72 , 33.02\n",
      "13.44 , 12.16\n",
      "4.8 , 5.41\n",
      "2.31 , 2.72\n",
      "81.95 , 63.85\n",
      "6.93 , 10.29\n",
      "0.99 , 0.85\n",
      "14.57 , 10.48\n",
      "15.54 , 15.76\n",
      "20.35 , 17.72\n",
      "[6.0293183]\n",
      "[0.2395324]\n",
      "[13.8546505]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 0.0004  and seed 42\n",
      "results for round: 0.0004  seed 42\n",
      "17.54 , 18.86\n",
      "1.93 , 1.64\n",
      "6.47 , 7.42\n",
      "3.62 , 3.91\n",
      "37.36 , 30.84\n",
      "71.23 , 90.17\n",
      "10.48 , 9.5\n",
      "53.71 , 32.13\n",
      "9.64 , 14.33\n",
      "40.89 , 36.27\n",
      "50.55 , 38.4\n",
      "7.31 , 4.49\n",
      "0.17 , 0.17\n",
      "18.4 , 17.66\n",
      "35.78 , 61.51\n",
      "11.53 , 13.95\n",
      "3.68 , 5.66\n",
      "11.83 , 14.49\n",
      "6.41 , 7.43\n",
      "0.5 , 0.4\n",
      "3.59 , 3.42\n",
      "218.4 , 252.68\n",
      "6.79 , 7.06\n",
      "218.54 , 308.13\n",
      "5.55 , 5.34\n",
      "15.16 , 11.02\n",
      "1.49 , 1.39\n",
      "3.47 , 3.12\n",
      "21.23 , 33.02\n",
      "11.38 , 12.16\n",
      "3.73 , 5.41\n",
      "2.09 , 2.72\n",
      "78.81 , 63.85\n",
      "6.04 , 10.29\n",
      "0.92 , 0.85\n",
      "11.59 , 10.48\n",
      "14.33 , 15.76\n",
      "16.37 , 17.72\n",
      "[7.2880707]\n",
      "[0.20184347]\n",
      "[17.289557]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 0.0002  and seed 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for round: 0.0002  seed 42\n",
      "17.73 , 18.86\n",
      "2.18 , 1.64\n",
      "6.52 , 7.42\n",
      "3.72 , 3.91\n",
      "38.67 , 30.84\n",
      "64.28 , 90.17\n",
      "10.65 , 9.5\n",
      "48.8 , 32.13\n",
      "8.93 , 14.33\n",
      "39.91 , 36.27\n",
      "48.04 , 38.4\n",
      "8.49 , 4.49\n",
      "0.19 , 0.17\n",
      "18.47 , 17.66\n",
      "37.56 , 61.51\n",
      "11.38 , 13.95\n",
      "4.01 , 5.66\n",
      "11.99 , 14.49\n",
      "6.35 , 7.43\n",
      "0.55 , 0.4\n",
      "3.81 , 3.42\n",
      "223.31 , 252.68\n",
      "6.84 , 7.06\n",
      "201.78 , 308.13\n",
      "5.63 , 5.34\n",
      "15.96 , 11.02\n",
      "1.74 , 1.39\n",
      "4.14 , 3.12\n",
      "20.81 , 33.02\n",
      "11.51 , 12.16\n",
      "3.79 , 5.41\n",
      "2.24 , 2.72\n",
      "75.24 , 63.85\n",
      "6.29 , 10.29\n",
      "0.97 , 0.85\n",
      "11.36 , 10.48\n",
      "14.52 , 15.76\n",
      "17.1 , 17.72\n",
      "[7.522129]\n",
      "[0.22634353]\n",
      "[19.36763]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 0.0001  and seed 42\n",
      "results for round: 0.0001  seed 42\n",
      "16.5 , 18.86\n",
      "2.13 , 1.64\n",
      "5.92 , 7.42\n",
      "3.42 , 3.91\n",
      "35.49 , 30.84\n",
      "59.73 , 90.17\n",
      "9.97 , 9.5\n",
      "45.6 , 32.13\n",
      "8.17 , 14.33\n",
      "42.53 , 36.27\n",
      "41.82 , 38.4\n",
      "7.8 , 4.49\n",
      "0.16 , 0.17\n",
      "17.07 , 17.66\n",
      "37.54 , 61.51\n",
      "10.53 , 13.95\n",
      "3.67 , 5.66\n",
      "11.13 , 14.49\n",
      "5.73 , 7.43\n",
      "0.47 , 0.4\n",
      "3.48 , 3.42\n",
      "206.41 , 252.68\n",
      "6.27 , 7.06\n",
      "192.66 , 308.13\n",
      "5.14 , 5.34\n",
      "14.95 , 11.02\n",
      "1.55 , 1.39\n",
      "3.49 , 3.12\n",
      "19.24 , 33.02\n",
      "10.59 , 12.16\n",
      "3.38 , 5.41\n",
      "2.07 , 2.72\n",
      "68.32 , 63.85\n",
      "5.7 , 10.29\n",
      "0.87 , 0.85\n",
      "10.23 , 10.48\n",
      "13.42 , 15.76\n",
      "15.89 , 17.72\n",
      "[8.075408]\n",
      "[0.21287009]\n",
      "[21.507957]\n",
      " \n",
      "next round!\n"
     ]
    }
   ],
   "source": [
    "#lstm\n",
    "epochs_per_round = 20\n",
    "seeds = [12,36,42]\n",
    "rounds_lr = [0.001,0.0008,0.0004,0.0002,0.0001]\n",
    "\n",
    "for seed in seeds:\n",
    "    print(\"______________________________________________\")\n",
    "    \n",
    "    n_samples = X.shape[0]\n",
    "    train_ind, test_ind  = train_test_split(range(n_samples), test_size=0.2, random_state=seed)\n",
    "\n",
    "    X_train = X[train_ind]\n",
    "    X_train_volume = X_volume[train_ind]\n",
    "    X_train_area = X_area[train_ind]\n",
    "    y_train = y[train_ind]\n",
    "\n",
    "    X_test = X[test_ind]\n",
    "    X_test_volume = X_volume[test_ind]\n",
    "    X_test_area = X_area[test_ind]\n",
    "    y_test = y[test_ind]\n",
    "\n",
    "    print(\"train\",X_train.shape,X_train_volume.shape,X_train_area.shape)\n",
    "    print(\"test\",X_test.shape,X_test_volume.shape,X_test_area.shape)\n",
    "\n",
    "    input1 = keras.Input(shape=(X_train.shape[1:]))\n",
    "    input2 = keras.Input(shape=(X_train_volume.shape[1:]))\n",
    "    input3 = keras.Input(shape=(X_train_area.shape[1:]))\n",
    "\n",
    "    activ = \"relu\"\n",
    "\n",
    "    # x = TimeDistributed(Convolution2D(32, (7, 7), activation='relu', padding='same'))(input1)\n",
    "    # x = TimeDistributed(Convolution2D(32, (7, 7), activation='relu', padding='same'))(x)\n",
    "    # x = TimeDistributed(MaxPooling2D(pool_size=(2, 2), padding='same'))(x)\n",
    "\n",
    "    x = TimeDistributed(Convolution2D(8, (3, 3), activation='relu', padding='same'))(input1)\n",
    "    x = TimeDistributed(Convolution2D(8, (3, 3), activation='relu', padding='same'))(x)\n",
    "    x = TimeDistributed(MaxPooling2D(pool_size=(2, 2), padding='same'))(x)\n",
    "    x = TimeDistributed(Convolution2D(4, (3, 3), activation='relu', padding='same'))(x)\n",
    "    x = TimeDistributed(Convolution2D(4, (3, 3), activation='relu', padding='same'))(x)\n",
    "    x = TimeDistributed(MaxPooling2D(pool_size=(2, 2), padding='same'))(x)\n",
    "    x = Dropout(0.30)(x)\n",
    "\n",
    "    x = TimeDistributed(Convolution2D(4, (3, 3), activation='relu', padding='same'))(x)\n",
    "    x = TimeDistributed(Convolution2D(4, (3, 3), activation='relu', padding='same'))(x)\n",
    "    x = TimeDistributed(MaxPooling2D(pool_size=(2, 2), padding='same'))(x)\n",
    "    x = Dropout(0.30)(x)\n",
    "    x = TimeDistributed(Flatten())(x)\n",
    "    x = LSTM(8, return_sequences=True, unroll=False, dropout=0.3)(x)  # dropout=0.6\n",
    "    x = LSTM(8, return_sequences=False, unroll=False, dropout=0.3)(x)\n",
    "\n",
    "\n",
    "    #x = layers.Concatenate(axis=1)([x,input2])\n",
    "\n",
    "    #x = Dense(4, activation = 'relu')(x)\n",
    "    x = layers.Concatenate(axis=1)([x,input3])\n",
    "\n",
    "    dense = Dense(2000, activation = activ)(x)\n",
    "    dense = Dense(300, activation = activ)(dense)\n",
    "    dense = Dense(150, activation = activ)(dense)\n",
    "    dense = Dense(20, activation = activ)(dense)\n",
    "    dense = Dense(16, activation = activ)(dense)\n",
    "        # final layer with 10 neurons to classify the instances\n",
    "    output = Dense(1, activation = 'linear')(dense)\n",
    "\n",
    "\n",
    "    model = keras.Model(inputs=[input1,input2,input3], outputs=output, name=\"jjlstmnet\")\n",
    "\n",
    "    for round_lr in rounds_lr:\n",
    "        print(\" \")\n",
    "        print(\"starting round lr\",round_lr,\" and seed\",seed)\n",
    "\n",
    "        model.compile(\n",
    "            loss=\"MAE\",\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=round_lr),\n",
    "            metrics=[\"MAPE\"],\n",
    "        )\n",
    "    \n",
    "    \n",
    "\n",
    "        model.fit([X_train,np.log(X_train_volume), np.log(X_train_area)], np.log(y_train), batch_size = 8, epochs = epochs_per_round, verbose = 0)\n",
    "        #model.fit([X_train,X_train_volume, X_train_area], np.log(y_train),validation_split = 0.2, batch_size = 8, epochs = 100, verbose = 1)\n",
    "        #model.evaluate([X_test, np.log(X_test_volume),np.log(X_test_area)],y_test)\n",
    "\n",
    "        preds = model.predict([X_test, np.log(X_test_volume),np.log(X_test_area)])#*y_train_max\n",
    "        #preds = model.predict([X_test,X_test_volume,X_test_area])#*y_train_max\n",
    "        \n",
    "        mae = 0\n",
    "        mape = 0\n",
    "        rmse = 0\n",
    "        c = 0\n",
    "        for e,i in zip(np.exp(preds),y_test):\n",
    "          mae = mae + abs(e-i)\n",
    "          mape = mape + abs((e-i)/i)\n",
    "          rmse = rmse + np.power((i-e),2)\n",
    "          c = c +1 \n",
    "          \n",
    "        print(\"results for round:\",round_lr,\" seed\",seed)\n",
    "        for e,i in zip(np.exp(preds),y_test):\n",
    "          print(round(e[0],2),\",\",round(i,2))\n",
    "\n",
    "        print(mae/c)\n",
    "        print(mape/c)\n",
    "        print(np.sqrt(rmse/c))\n",
    "        print(\" \")\n",
    "        print(\"next round!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________\n",
      "train (750, 100, 100, 100, 1) (750, 1) (750, 1)\n",
      "test (38, 100, 100, 100, 1) (38, 1) (38, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 15:43:13.050726: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-05 15:43:13.102364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 0 with properties: \n",
      "pciBusID: 0000:21:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-01-05 15:43:13.102449: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-05 15:43:13.116326: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcublas.so.11\n",
      "2022-01-05 15:43:13.116409: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-01-05 15:43:13.123318: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-05 15:43:13.125248: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-05 15:43:13.142063: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcutensor.so.1\n",
      "2022-01-05 15:43:13.144145: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-01-05 15:43:13.148662: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-01-05 15:43:13.149475: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-01-05 15:43:13.150659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1872] Adding visible gpu devices: 0\n",
      "2022-01-05 15:43:13.152260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 0 with properties: \n",
      "pciBusID: 0000:21:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-01-05 15:43:13.152573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1872] Adding visible gpu devices: 0\n",
      "2022-01-05 15:43:13.152821: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-05 15:43:14.016143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-01-05 15:43:14.016199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-01-05 15:43:14.016240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-01-05 15:43:14.017056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9649 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:21:00.0, compute capability: 7.5)\n",
      "2022-01-05 15:43:14.018335: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 20. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "starting round lr 0.0001  and seed 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 15:43:16.492740: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-01-05 15:43:16.512430: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3299990000 Hz\n",
      "2022-01-05 15:43:17.142239: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-01-05 15:43:17.863745: I tensorflow/stream_executor/cuda/cuda_dnn.cc:380] Loaded cuDNN version 8202\n",
      "2022-01-05 15:43:18.702007: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcublas.so.11\n",
      "2022-01-05 15:43:19.493647: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for round: 0.0001  seed 12\n",
      "10.34 , 12.72\n",
      "38.29 , 57.87\n",
      "7.11 , 8.32\n",
      "0.54 , 0.44\n",
      "11.94 , 12.48\n",
      "2.78 , 3.61\n",
      "138.98 , 132.82\n",
      "90.52 , 181.63\n",
      "6.84 , 10.26\n",
      "7.62 , 7.88\n",
      "1.03 , 1.01\n",
      "45.73 , 61.96\n",
      "7.53 , 7.07\n",
      "5.51 , 5.34\n",
      "7.83 , 7.06\n",
      "29.79 , 38.64\n",
      "37.65 , 38.24\n",
      "19.52 , 21.83\n",
      "50.61 , 46.66\n",
      "107.41 , 171.18\n",
      "8.61 , 7.76\n",
      "136.7 , 121.39\n",
      "3.37 , 10.55\n",
      "77.6 , 65.15\n",
      "20.79 , 18.86\n",
      "11.44 , 12.16\n",
      "34.63 , 40.57\n",
      "4.58 , 4.62\n",
      "34.04 , 36.27\n",
      "6.26 , 5.85\n",
      "1.89 , 2.72\n",
      "0.68 , 0.82\n",
      "78.11 , 90.17\n",
      "21.88 , 21.26\n",
      "3.62 , 3.35\n",
      "72.67 , 87.23\n",
      "20.66 , 53.01\n",
      "0.53 , 0.45\n",
      "[8.702759]\n",
      "[0.17469321]\n",
      "[19.910677]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 8e-05  and seed 12\n",
      "results for round: 8e-05  seed 12\n",
      "13.48 , 12.72\n",
      "43.77 , 57.87\n",
      "7.05 , 8.32\n",
      "0.57 , 0.44\n",
      "12.68 , 12.48\n",
      "2.66 , 3.61\n",
      "178.6 , 132.82\n",
      "86.57 , 181.63\n",
      "6.73 , 10.26\n",
      "7.82 , 7.88\n",
      "1.02 , 1.01\n",
      "52.09 , 61.96\n",
      "7.64 , 7.07\n",
      "5.59 , 5.34\n",
      "8.04 , 7.06\n",
      "33.81 , 38.64\n",
      "40.16 , 38.24\n",
      "21.84 , 21.83\n",
      "56.48 , 46.66\n",
      "110.01 , 171.18\n",
      "8.91 , 7.76\n",
      "164.51 , 121.39\n",
      "3.25 , 10.55\n",
      "78.01 , 65.15\n",
      "20.28 , 18.86\n",
      "11.46 , 12.16\n",
      "36.55 , 40.57\n",
      "4.68 , 4.62\n",
      "35.76 , 36.27\n",
      "6.53 , 5.85\n",
      "1.98 , 2.72\n",
      "0.68 , 0.82\n",
      "82.96 , 90.17\n",
      "24.44 , 21.26\n",
      "3.5 , 3.35\n",
      "81.72 , 87.23\n",
      "25.68 , 53.01\n",
      "0.55 , 0.45\n",
      "[9.6694765]\n",
      "[0.17672972]\n",
      "[21.914803]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 4e-05  and seed 12\n",
      "results for round: 4e-05  seed 12\n",
      "14.41 , 12.72\n",
      "43.95 , 57.87\n",
      "7.33 , 8.32\n",
      "0.55 , 0.44\n",
      "12.88 , 12.48\n",
      "2.55 , 3.61\n",
      "171.38 , 132.82\n",
      "96.04 , 181.63\n",
      "6.86 , 10.26\n",
      "8.03 , 7.88\n",
      "1.03 , 1.01\n",
      "53.52 , 61.96\n",
      "7.75 , 7.07\n",
      "5.73 , 5.34\n",
      "8.18 , 7.06\n",
      "36.46 , 38.64\n",
      "41.28 , 38.24\n",
      "23.29 , 21.83\n",
      "58.26 , 46.66\n",
      "115.75 , 171.18\n",
      "9.01 , 7.76\n",
      "170.93 , 121.39\n",
      "3.45 , 10.55\n",
      "75.97 , 65.15\n",
      "20.18 , 18.86\n",
      "12.28 , 12.16\n",
      "38.45 , 40.57\n",
      "4.76 , 4.62\n",
      "36.42 , 36.27\n",
      "6.4 , 5.85\n",
      "2.13 , 2.72\n",
      "0.68 , 0.82\n",
      "85.71 , 90.17\n",
      "24.0 , 21.26\n",
      "3.72 , 3.35\n",
      "87.1 , 87.23\n",
      "29.28 , 53.01\n",
      "0.54 , 0.45\n",
      "[8.830358]\n",
      "[0.16895415]\n",
      "[20.223103]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 2e-05  and seed 12\n",
      "results for round: 2e-05  seed 12\n",
      "13.93 , 12.72\n",
      "41.77 , 57.87\n",
      "7.0 , 8.32\n",
      "0.54 , 0.44\n",
      "12.41 , 12.48\n",
      "2.5 , 3.61\n",
      "165.56 , 132.82\n",
      "86.27 , 181.63\n",
      "6.54 , 10.26\n",
      "7.77 , 7.88\n",
      "1.01 , 1.01\n",
      "50.79 , 61.96\n",
      "7.43 , 7.07\n",
      "5.47 , 5.34\n",
      "7.72 , 7.06\n",
      "34.28 , 38.64\n",
      "39.88 , 38.24\n",
      "22.09 , 21.83\n",
      "49.27 , 46.66\n",
      "109.6 , 171.18\n",
      "8.53 , 7.76\n",
      "156.94 , 121.39\n",
      "3.29 , 10.55\n",
      "72.88 , 65.15\n",
      "18.95 , 18.86\n",
      "11.58 , 12.16\n",
      "36.25 , 40.57\n",
      "4.6 , 4.62\n",
      "35.21 , 36.27\n",
      "6.15 , 5.85\n",
      "2.05 , 2.72\n",
      "0.66 , 0.82\n",
      "83.91 , 90.17\n",
      "22.87 , 21.26\n",
      "3.57 , 3.35\n",
      "82.77 , 87.23\n",
      "28.16 , 53.01\n",
      "0.53 , 0.45\n",
      "[8.699536]\n",
      "[0.15693891]\n",
      "[20.81662]\n",
      " \n",
      "next round!\n",
      "______________________________________________\n",
      "train (750, 100, 100, 100, 1) (750, 1) (750, 1)\n",
      "test (38, 100, 100, 100, 1) (38, 1) (38, 1)\n",
      " \n",
      "starting round lr 0.0001  and seed 36\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff82b856ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "results for round: 0.0001  seed 36\n",
      "67.0 , 65.15\n",
      "4.32 , 3.35\n",
      "13.84 , 12.19\n",
      "6.21 , 4.33\n",
      "2.09 , 2.72\n",
      "13.61 , 14.49\n",
      "80.72 , 107.3\n",
      "6.34 , 5.86\n",
      "5.86 , 6.58\n",
      "39.02 , 30.78\n",
      "45.09 , 49.05\n",
      "1.95 , 3.12\n",
      "14.89 , 16.09\n",
      "4.45 , 5.15\n",
      "0.96 , 1.24\n",
      "78.66 , 60.7\n",
      "44.44 , 81.17\n",
      "66.04 , 66.36\n",
      "2.29 , 1.76\n",
      "37.22 , 34.17\n",
      "35.57 , 36.27\n",
      "27.0 , 29.22\n",
      "61.52 , 54.11\n",
      "18.23 , 19.35\n",
      "152.97 , 121.39\n",
      "2.0 , 1.93\n",
      "116.73 , 126.5\n",
      "13.16 , 12.32\n",
      "141.15 , 160.8\n",
      "39.26 , 35.34\n",
      "5.96 , 6.8\n",
      "5.66 , 4.05\n",
      "1.84 , 1.64\n",
      "6.06 , 5.79\n",
      "85.52 , 87.23\n",
      "51.93 , 38.22\n",
      "84.89 , 90.17\n",
      "22.18 , 34.65\n",
      "[5.873076]\n",
      "[0.16801567]\n",
      "[10.786511]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 8e-05  and seed 36\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff8dd30a280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "results for round: 8e-05  seed 36\n",
      "65.24 , 65.15\n",
      "3.62 , 3.35\n",
      "12.44 , 12.19\n",
      "6.01 , 4.33\n",
      "2.01 , 2.72\n",
      "13.56 , 14.49\n",
      "74.17 , 107.3\n",
      "6.57 , 5.86\n",
      "5.8 , 6.58\n",
      "36.61 , 30.78\n",
      "48.95 , 49.05\n",
      "1.56 , 3.12\n",
      "14.81 , 16.09\n",
      "3.72 , 5.15\n",
      "0.95 , 1.24\n",
      "73.25 , 60.7\n",
      "46.16 , 81.17\n",
      "60.75 , 66.36\n",
      "1.91 , 1.76\n",
      "35.74 , 34.17\n",
      "28.89 , 36.27\n",
      "24.38 , 29.22\n",
      "56.49 , 54.11\n",
      "16.87 , 19.35\n",
      "156.88 , 121.39\n",
      "1.81 , 1.93\n",
      "118.24 , 126.5\n",
      "12.38 , 12.32\n",
      "109.36 , 160.8\n",
      "37.83 , 35.34\n",
      "5.85 , 6.8\n",
      "5.42 , 4.05\n",
      "1.79 , 1.64\n",
      "5.11 , 5.79\n",
      "85.66 , 87.23\n",
      "50.09 , 38.22\n",
      "87.91 , 90.17\n",
      "18.39 , 34.65\n",
      "[6.6834574]\n",
      "[0.16772152]\n",
      "[13.617243]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 4e-05  and seed 36\n",
      "results for round: 4e-05  seed 36\n",
      "62.47 , 65.15\n",
      "3.22 , 3.35\n",
      "11.72 , 12.19\n",
      "5.62 , 4.33\n",
      "1.95 , 2.72\n",
      "12.75 , 14.49\n",
      "70.91 , 107.3\n",
      "6.25 , 5.86\n",
      "5.53 , 6.58\n",
      "34.1 , 30.78\n",
      "48.11 , 49.05\n",
      "1.55 , 3.12\n",
      "14.16 , 16.09\n",
      "3.54 , 5.15\n",
      "0.98 , 1.24\n",
      "67.33 , 60.7\n",
      "42.82 , 81.17\n",
      "58.74 , 66.36\n",
      "1.76 , 1.76\n",
      "33.22 , 34.17\n",
      "28.02 , 36.27\n",
      "22.89 , 29.22\n",
      "48.49 , 54.11\n",
      "16.27 , 19.35\n",
      "149.05 , 121.39\n",
      "1.78 , 1.93\n",
      "112.94 , 126.5\n",
      "12.16 , 12.32\n",
      "110.4 , 160.8\n",
      "35.33 , 35.34\n",
      "5.6 , 6.8\n",
      "5.54 , 4.05\n",
      "1.68 , 1.64\n",
      "4.81 , 5.79\n",
      "82.9 , 87.23\n",
      "45.68 , 38.22\n",
      "84.25 , 90.17\n",
      "18.05 , 34.65\n",
      "[6.8776126]\n",
      "[0.16731265]\n",
      "[13.53491]\n",
      " \n",
      "next round!\n",
      " \n",
      "starting round lr 2e-05  and seed 36\n",
      "results for round: 2e-05  seed 36\n",
      "64.83 , 65.15\n",
      "3.42 , 3.35\n",
      "12.41 , 12.19\n",
      "5.72 , 4.33\n",
      "2.05 , 2.72\n",
      "13.11 , 14.49\n",
      "74.71 , 107.3\n",
      "6.74 , 5.86\n",
      "5.9 , 6.58\n",
      "36.04 , 30.78\n",
      "50.94 , 49.05\n",
      "1.68 , 3.12\n",
      "14.63 , 16.09\n",
      "3.83 , 5.15\n",
      "1.02 , 1.24\n",
      "70.62 , 60.7\n",
      "44.84 , 81.17\n",
      "61.51 , 66.36\n",
      "1.93 , 1.76\n",
      "34.5 , 34.17\n",
      "29.5 , 36.27\n",
      "23.63 , 29.22\n",
      "50.04 , 54.11\n",
      "16.76 , 19.35\n",
      "162.15 , 121.39\n",
      "1.88 , 1.93\n",
      "120.11 , 126.5\n",
      "12.54 , 12.32\n",
      "117.07 , 160.8\n",
      "36.75 , 35.34\n",
      "5.96 , 6.8\n",
      "5.72 , 4.05\n",
      "1.77 , 1.64\n",
      "5.14 , 5.79\n",
      "87.95 , 87.23\n",
      "47.09 , 38.22\n",
      "89.59 , 90.17\n",
      "18.79 , 34.65\n",
      "[6.377231]\n",
      "[0.15826067]\n",
      "[13.179077]\n",
      " \n",
      "next round!\n",
      "______________________________________________\n"
     ]
    }
   ],
   "source": [
    "#aug vox !!!\n",
    "\n",
    "#vox \n",
    "epochs_per_round = 100\n",
    "seeds = [12,36,42]\n",
    "#seeds = [42]\n",
    "rounds_lr = [0.0001,0.00008,0.00004,0.00002]\n",
    "\n",
    "for seed in seeds:\n",
    "\n",
    "    print(\"______________________________________________\")\n",
    "    \n",
    "    path_split = str(pathlib.Path().resolve())+\"/dataset/\"+str(seed)\n",
    "\n",
    "    X_train = np.load(path_split+\"/X_train.npy\")\n",
    "    X_train_volume = np.load(path_split+\"/X_train_volume.npy\")\n",
    "    X_train_area = np.load(path_split+\"/X_train_area.npy\")\n",
    "    y_train = np.load(path_split+\"/y_train.npy\")\n",
    "\n",
    "    X_test = np.load(path_split+\"/X_test.npy\")\n",
    "    X_test_volume = np.load(path_split+\"/X_test_volume.npy\")\n",
    "    X_test_area = np.load(path_split+\"/X_test_area.npy\")\n",
    "    y_test = np.load(path_split+\"/y_test.npy\")\n",
    "\n",
    "    \n",
    "    print(\"train\",X_train.shape,X_train_volume.shape,X_train_area.shape)\n",
    "    print(\"test\",X_test.shape,X_test_volume.shape,X_test_area.shape)\n",
    "\n",
    "    #my net\n",
    "    input1 = keras.Input(shape=(X_train.shape[1:]))\n",
    "    input2 = keras.Input(shape=(X_train_volume.shape[1:]))\n",
    "    input3 = keras.Input(shape=(X_train_area.shape[1:]))\n",
    "\n",
    "    #y = Dense(1)(input2)\n",
    "    activ = \"LeakyReLU\"\n",
    "    # x = Conv3D(64,(7,7,7),strides = (2,2,2), activation=activ, padding = 'same')(input1)\n",
    "    # x = Conv3D(64,(7,7,7),strides = (2,2,2), activation=activ, padding = 'same')(x)\n",
    "    # x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "    # x = layers.Dropout(0.3)(x)\n",
    "    n=3\n",
    "    x = Conv3D(32,(n,n,n),strides = (2,2,2), activation=activ, padding = 'same')(input1)\n",
    "    x = Conv3D(32,(n,n,n),strides = (2,2,2), activation=activ, padding = 'same')(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv3D(16,(n,n,n), activation=activ, padding = 'same')(x)\n",
    "    x = Conv3D(16,(n,n,n),strides = (2,2,2), activation=activ, padding = 'same')(x)\n",
    "    x = MaxPooling3D(pool_size=(1, 1, 1))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv3D(8,(n,n,n),strides = (2,2,2), activation=activ, padding = 'same')(x)\n",
    "    x = Conv3D(8,(n,n,n),strides = (2,2,2), activation=activ, padding = 'same')(x)\n",
    "    x = MaxPooling3D(pool_size=(1, 1, 1))(x)\n",
    "\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = layers.Concatenate(axis=1)([x,input2])\n",
    "    x = Dense(4, activation = 'relu')(x)\n",
    "    x = layers.Concatenate(axis=1)([x,input3])\n",
    "\n",
    "    dense = Dense(2000, activation = activ)(x)\n",
    "    dense = Dense(300, activation = activ)(dense)\n",
    "    dense = Dense(150, activation = activ)(dense)\n",
    "    dense = Dense(20, activation = activ)(dense)\n",
    "    dense = Dense(16, activation = activ)(dense)\n",
    "        # final layer with 10 neurons to classify the instances\n",
    "    output = Dense(1, activation = 'linear')(dense)\n",
    "\n",
    "    #outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input1,input2,input3], outputs=output, name=\"jjnet\")\n",
    "\n",
    "    for round_lr in rounds_lr:\n",
    "        \n",
    "        print(\" \")\n",
    "        print(\"starting round lr\",round_lr,\" and seed\",seed)\n",
    "\n",
    "        model.compile(\n",
    "            loss=\"MAE\",\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=round_lr),\n",
    "            metrics=[\"MAPE\"],\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        model.fit([X_train,np.log(X_train_volume), np.log(X_train_area)], np.log(y_train), batch_size = 8, epochs = epochs_per_round, verbose = 0)\n",
    "        #model.fit([X_train,X_train_volume, X_train_area], np.log(y_train),validation_split = 0.2, batch_size = 8, epochs = 100, verbose = 1)\n",
    "        #model.evaluate([X_test, np.log(X_test_volume),np.log(X_test_area)],y_test)\n",
    "\n",
    "        preds = model.predict([X_test, np.log(X_test_volume),np.log(X_test_area)])#*y_train_max\n",
    "        #preds = model.predict([X_test,X_test_volume,X_test_area])#*y_train_max\n",
    "\n",
    "        mae = 0\n",
    "        mape = 0\n",
    "        rmse = 0\n",
    "        c = 0\n",
    "        for e,i in zip(np.exp(preds),y_test):\n",
    "          mae = mae + abs(e-i)\n",
    "          mape = mape + abs((e-i)/i)\n",
    "          rmse = rmse + np.power((i-e),2)\n",
    "          c = c +1 \n",
    "\n",
    "        print(\"results for round:\",round_lr,\" seed\",seed)\n",
    "        for e,i in zip(np.exp(preds),y_test):\n",
    "          print(round(e[0],2),\",\",round(i,2))\n",
    "\n",
    "        print(mae/c)\n",
    "        print(mape/c)\n",
    "        print(np.sqrt(rmse/c))\n",
    "        print(\" \")\n",
    "        print(\"next round!\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________\n",
      "train (150, 100, 100, 100, 1) (150, 1) (150, 1)\n",
      "test (38, 100, 100, 100, 1) (38, 1) (38, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='input_39'), name='input_39', description=\"created by layer 'input_39'\") at layer \"concatenate_10\". The following previous layers were accessed without issue: ['conv3d_51', 'conv3d_52', 'max_pooling3d_24', 'dropout_33', 'conv3d_53', 'conv3d_54', 'max_pooling3d_25', 'dropout_34', 'conv3d_55', 'dropout_35', 'flatten_12', 'concatenate_9']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_54853/3415514225.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m#outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"papernet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mround_lr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrounds_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFunctional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     nodes, nodes_by_depth, layers, _ = _map_graph_network(\n\u001b[0m\u001b[1;32m    199\u001b[0m         self.inputs, self.outputs)\n\u001b[1;32m    200\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             raise ValueError('Graph disconnected: '\n\u001b[0m\u001b[1;32m    986\u001b[0m                              \u001b[0;34m'cannot obtain value for tensor '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                              \u001b[0;34m' at layer \"'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\". '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='input_39'), name='input_39', description=\"created by layer 'input_39'\") at layer \"concatenate_10\". The following previous layers were accessed without issue: ['conv3d_51', 'conv3d_52', 'max_pooling3d_24', 'dropout_33', 'conv3d_53', 'conv3d_54', 'max_pooling3d_25', 'dropout_34', 'conv3d_55', 'dropout_35', 'flatten_12', 'concatenate_9']"
     ]
    }
   ],
   "source": [
    "#PAPERNET\n",
    "epochs_per_round = 20\n",
    "seeds = [12,36,42]\n",
    "rounds_lr = [0.001,0.0008,0.0004,0.0002,0.0001]\n",
    "\n",
    "for seed in seeds:\n",
    "    print(\"______________________________________________\")\n",
    "    \n",
    "    n_samples = X.shape[0]\n",
    "    train_ind, test_ind  = train_test_split(range(n_samples), test_size=0.2, random_state=seed)\n",
    "\n",
    "    X_train = X[train_ind]\n",
    "    X_train_volume = X_volume[train_ind]\n",
    "    X_train_area = X_area[train_ind]\n",
    "    y_train = y[train_ind]\n",
    "\n",
    "    X_test = X[test_ind]\n",
    "    X_test_volume = X_volume[test_ind]\n",
    "    X_test_area = X_area[test_ind]\n",
    "    y_test = y[test_ind]\n",
    "\n",
    "    print(\"train\",X_train.shape,X_train_volume.shape,X_train_area.shape)\n",
    "    print(\"test\",X_test.shape,X_test_volume.shape,X_test_area.shape)\n",
    "\n",
    "    #@title Default title text\n",
    "    #paper net \n",
    "    input1 = keras.Input(shape=(X_train.shape[1:]))\n",
    "    input2 = keras.Input(shape=(X_train_volume.shape[1:]))\n",
    "    input3 = keras.Input(shape=(X_train_area.shape[1:]))\n",
    "\n",
    "    x = Conv3D(16,(3,3,3), activation='LeakyReLU', padding = 'same')(input1)\n",
    "    x = Conv3D(16,(3,3,3), activation='LeakyReLU', padding = 'same')(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv3D(32,(3,3,3), activation='LeakyReLU', padding = 'same')(x)\n",
    "    x = Conv3D(32,(3,3,3), activation='LeakyReLU', padding = 'same')(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv3D(8,(3,3,3), activation='LeakyReLU', padding = 'same')(x)\n",
    "\n",
    "    x = layers.Dropout(0.8)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = layers.Concatenate(axis=1)([x,input2])\n",
    "    x = layers.Concatenate(axis=1)([x,input3])\n",
    "\n",
    "\n",
    "    x = Dense(8, activation = 'LeakyReLU')(x)\n",
    "    dense = Dense(2000, activation = 'LeakyReLU')(x)\n",
    "    dense = Dense(300, activation = 'LeakyReLU')(dense)\n",
    "    dense = Dense(150, activation = 'LeakyReLU')(dense)\n",
    "    dense = Dense(20, activation = 'LeakyReLU')(dense)\n",
    "    dense = Dense(16, activation = 'LeakyReLU')(dense)\n",
    "        # final layer with 10 neurons to classify the instances\n",
    "    output = Dense(1, activation = 'linear')(dense)\n",
    "\n",
    "    #outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input1,input2], outputs=output, name=\"papernet\")\n",
    "\n",
    "    for round_lr in rounds_lr:\n",
    "        print(\" \")\n",
    "        print(\"starting round lr\",round_lr,\" and seed\",seed)\n",
    "\n",
    "        model.compile(\n",
    "            loss=\"MAE\",\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=round_lr),\n",
    "            metrics=[\"MAPE\"],\n",
    "        )\n",
    "    \n",
    "    \n",
    "        model.fit([X_train,np.log(X_train_volume), np.log(X_train_area)], np.log(y_train), batch_size = 8, epochs = epochs_per_round, verbose = 1)\n",
    "        #model.fit([X_train,X_train_volume, X_train_area], np.log(y_train),validation_split = 0.2, batch_size = 8, epochs = 100, verbose = 1)\n",
    "        #model.evaluate([X_test, np.log(X_test_volume),np.log(X_test_area)],y_test)\n",
    "\n",
    "        preds = model.predict([X_test, np.log(X_test_volume),np.log(X_test_area)])#*y_train_max\n",
    "        #preds = model.predict([X_test,X_test_volume,X_test_area])#*y_train_max\n",
    "        \n",
    "        mae = 0\n",
    "        mape = 0\n",
    "        rmse = 0\n",
    "        c = 0\n",
    "        for e,i in zip(np.exp(preds),y_test):\n",
    "          mae = mae + abs(e-i)\n",
    "          mape = mape + abs((e-i)/i)\n",
    "          rmse = rmse + np.power((i-e),2)\n",
    "          c = c +1 \n",
    "          \n",
    "        print(\"results for round:\",round_lr,\" seed\",seed)\n",
    "        for e,i in zip(np.exp(preds),y_test):\n",
    "          print(round(e[0],2),\",\",round(i,2))\n",
    "\n",
    "        print(mae/c)\n",
    "        print(mape/c)\n",
    "        print(np.sqrt(rmse/c))\n",
    "        print(\" \")\n",
    "        print(\"next round!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "mppd.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "50ffb7d2e1c20b3fce74969edadf992c5e2c62f97786e5c092ebf6cc72a542c6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
